{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68f42ebc",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# Further Reading\n",
    "\n",
    "1.  Memory allocation is an important concept of a machine learning\n",
    "    backend. For further reading, see *Training Deep Nets with Sublinear\n",
    "    Memory Cost*[^1] and *Dynamic Tensor Rematerialization*[^2].\n",
    "\n",
    "2.  For more about runtime scheduling and execution, see A *Lightweight\n",
    "    Parallel and Heterogeneous Task Graph Computing System*[^3],\n",
    "    *Dynamic Control Flow in Large-Scale Machine Learning*[^4], and\n",
    "    *Deep Learning with Dynamic Computation Graphs*[^5].\n",
    "\n",
    "3.  For further reading about operator compilers, see *Halide: A\n",
    "    Language and Compiler for Optimizing Parallelism, Locality, and\n",
    "    Recomputation in Image Processing Pipelines*[^6], *Ansor: Generating\n",
    "    High-Performance Tensor Programs for Deep Learning*[^7], and\n",
    "    *Polly - Polyhedral optimization in LLVM*[^8].\n",
    "\n",
    "4.  One of challenges faced by modern deep learning compiler frameworks\n",
    "    is to achieve performance levels comparable to manually optimized\n",
    "    libraries that are specific to the target platform. To address this\n",
    "    challenge, auto-tuning frameworks utilize statistical cost models to\n",
    "    dynamically and efficiently optimize code. However, these frameworks\n",
    "    also have certain drawbacks, such as the need for extensive\n",
    "    exploration and training overheads in order to establish the cost\n",
    "    model. Recent work, like *MetaTune: Meta-Learning Based Cost Model\n",
    "    for Fast and Efficient Auto-tuning Frameworks*[^9] predicts the\n",
    "    performance of optimized codes with pre-trained model parameters.\n",
    "\n",
    "[^1]: <https://arxiv.org/abs/1604.06174>\n",
    "\n",
    "[^2]: <https://arxiv.org/abs/2006.09616>\n",
    "\n",
    "[^3]: <https://arxiv.org/abs/2004.10908>\n",
    "\n",
    "[^4]: <https://arxiv.org/abs/1805.01772>\n",
    "\n",
    "[^5]: <https://arxiv.org/abs/1702.02181>\n",
    "\n",
    "[^6]: <https://dl.acm.org/doi/abs/10.1145/2499370.2462176>\n",
    "\n",
    "[^7]: <https://arxiv.org/abs/2006.06762>\n",
    "\n",
    "[^8]: <https://arxiv.org/abs/2105.04555>\n",
    "\n",
    "[^9]: <https://arxiv.org/abs/2102.04199>\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}