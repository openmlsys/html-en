{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1bee775",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# Parameter Server\n",
    ":label:`parameter server`\n",
    "\n",
    "The following describes another common distributed training system:\n",
    "parameter server. In different machine learning frameworks, the\n",
    "parameter server may be implemented in different ways. For example,\n",
    "while TensorFlow and MindSpore come with built-in parameter server\n",
    "implementations, PyTorch requires users to implement the parameter\n",
    "servers themselves by using RPC interfaces.\n",
    "\n",
    "![Architecture of a parameter serversystem](../img/ch10/ch10-parameter-servers.png)\n",
    ":label:`ch010/ch10-parameter-servers`\n",
    "\n",
    "## System Architecture\n",
    "\n",
    "Different from the machine learning systems implemented based on\n",
    "collective communication, the parameter server system assigns two roles\n",
    "to servers: training server or parameter server. The parameter server\n",
    "needs to provide sufficient memory and communication resources, whereas\n",
    "the training server needs to provide a large quantity of computing\n",
    "resources (e.g., hardware accelerators).\n",
    "\n",
    "Figure :numref:`ch010/ch10-parameter-servers` depicts a machine learning\n",
    "cluster with two training servers and two parameter servers. Assume we\n",
    "have a model that can be divided into two parameter partitions. Each\n",
    "partition is assigned to a parameter server for synchronizing\n",
    "parameters. In the training process, each training server has a complete\n",
    "model to train a gradient based on the local training dataset shard. The\n",
    "gradient is then pushed to the corresponding parameter server. After the\n",
    "two training servers push their gradients, the parameter servers start\n",
    "to compute the average gradient and update parameters accordingly. The\n",
    "parameter servers then request the training servers to pull the latest\n",
    "parameters and start the next round of training iteration.\n",
    "\n",
    "## Asynchronous Distributed Training\n",
    "\n",
    "As discussed earlier, after each round of training, training servers\n",
    "need to compute an average gradient to update each model replica. This\n",
    "is necessary to ensure that the parameters of all model replicas are\n",
    "consistent before the next round of training begins. Such implementation\n",
    "is generally referred to as *synchronous training*.\n",
    "\n",
    "Although synchronous training helps the training system achieve higher\n",
    "model accuracy, in a large system, stragglers often appear due to\n",
    "various causes. Common causes include: 1) The stragglers may not be in\n",
    "the same rack as other devices. Therefore, the communication bandwidth\n",
    "of the stragglers is significantly lower than that of the other devices.\n",
    "2) The stragglers may share local computing and communication resources\n",
    "with other processes, resulting in resource contention and performance\n",
    "degradation.\n",
    "\n",
    "Stragglers will significantly impact the performance of AllReduce-based\n",
    "synchronous training systems. This is because, in such systems, all\n",
    "nodes participate in average-gradient computation and communication.\n",
    "Therefore, the emergence of any straggler will delay the entire\n",
    "AllReduce operation. To solve this problem, we could use a parameter\n",
    "server that realizes *asynchronous training* of models.\n",
    "\n",
    "In an asynchronous training system, all training servers have the same\n",
    "model parameter replica at the outset of training. During training, once\n",
    "they finish computing gradients, the training servers immediately push\n",
    "the results to the parameter server. Based on the received gradients,\n",
    "the parameter server immediately updates model parameters and requests\n",
    "training servers to pull the latest parameters. In this process,\n",
    "different training servers are likely to use model parameters of\n",
    "different versions for gradient computation. While this method may\n",
    "negatively affect model accuracy, it enables different training servers\n",
    "to push and pull parameters based on their operation speeds rather than\n",
    "waiting for their peers. In this sense, stragglers will not affect the\n",
    "performance of the entire cluster.\n",
    "\n",
    "### Training Sparse Models\n",
    "\n",
    "A substantial number of large-scale machine learning models exhibit\n",
    "*sparsity*, which signifies that only a subset of their parameters\n",
    "become activated when a model training or inference request is\n",
    "processed. An illustrative example of this can be found in recommender\n",
    "systems, where a sizable embedding table is stored on parameter servers.\n",
    "In response to an inference request for a specific user, the parameter\n",
    "server retrieves only the embedding pertinent to that user. A similar\n",
    "scenario can be observed in mixture-of-expert models, in which a limited\n",
    "number of experts are activated to process input data, contingent on the\n",
    "data's characteristics.\n",
    "\n",
    "Parameter servers can be especially beneficial in streamlining the\n",
    "training of sparse machine learning models. This advantage stems from\n",
    "the ability to store the sparse models on the parameter servers, leaving\n",
    "the dense models---often neural networks---on the training servers where\n",
    "sophisticated hardware accelerators are deployed. Operating with a lower\n",
    "resource footprint, parameter servers mainly necessitate an adequate\n",
    "supply of memory and network resources, rather than the more expensive\n",
    "parallel cores utilized by CPUs and GPUs. As a result, this approach\n",
    "significantly cuts costs when accommodating large sparse models. This is\n",
    "in contrast to the more expensive strategy which relies solely on GPU\n",
    "servers---coordinated through collective communication---to host both\n",
    "sparse and dense models. This practice incurs significantly higher\n",
    "costs.\n",
    "\n",
    "## Model Replication\n",
    "\n",
    "In this section, we will discuss the ways parameter servers utilize\n",
    "model replication to address issues related to data hotspots and server\n",
    "failures.\n",
    "\n",
    "### Addressing Data Hotspots\n",
    "\n",
    "Data on the internet typically follows a power-law distribution, which\n",
    "means that certain parameters are accessed more often than others during\n",
    "training. For instance, the embedding item of a widely popular commodity\n",
    "may be pulled by training servers much more frequently than one from a\n",
    "less popular commodity. This disparity can result in a parameter server,\n",
    "storing such popular data, being burdened with a disproportionately high\n",
    "volume of data pull and push requests, leading to data hotspots that can\n",
    "undermine system scalability.\n",
    "\n",
    "To mitigate data hotspots, a machine learning cluster can monitor the\n",
    "access frequency of each model parameter. It can then create multiple\n",
    "replicas of frequently accessed parameters, distributing them across\n",
    "different parameter servers. To facilitate this, a router is created\n",
    "which directs a parameter query to an appropriate parameter replica.\n",
    "Within this router, strategies such as random routing or round-robin\n",
    "routing can be implemented to ensure a balanced access workload across\n",
    "all replicas.\n",
    "\n",
    "### Managing Server Failures\n",
    "\n",
    "Parameter servers are typically deployed for extended periods, enabling\n",
    "training servers or inference servers to continually query and update\n",
    "parameters. During this time, some parameter servers may experience\n",
    "failures due to hardware issues (such as disk, memory, and processors)\n",
    "or network partitions caused by network switch failures or network\n",
    "misconfigurations.\n",
    "\n",
    "To combat server failures, parameter servers can create replicas of all\n",
    "parameters and distribute these replicas across different servers. This\n",
    "distribution decreases the chance that these servers will fail\n",
    "simultaneously. Generally, these replicas are located on servers placed\n",
    "in separate racks, clusters, and data centers to further minimize risk.\n",
    "\n",
    "### Maintaining Replica Consistency\n",
    "\n",
    "Both training and inference servers can update a parameter replicated on\n",
    "different servers. To ensure consistency amongst these replicas,\n",
    "parameter servers must employ a replication protocol to coordinate\n",
    "simultaneous updates on parameter replicas. A commonly utilized protocol\n",
    "is the Leader-Follower replication. This protocol designates one of the\n",
    "replicas as a leader and synchronizes all update operations on training\n",
    "servers to this leader replica before propagating the updates to the\n",
    "follower replicas.\n",
    "\n",
    "Deciding on the leader replica and synchronizing updates between the\n",
    "leader and follower replicas are enduring challenges in the field of\n",
    "distributed systems. To address these challenges, industry professionals\n",
    "have developed numerous robust algorithms, such as Paxos and Raft.\n",
    "\n",
    "Moreover, striking a balance between availability and consistency when\n",
    "replicating updates is another key concern. A strong-consistency\n",
    "replication protocol, like chain replication, may lead to failure of the\n",
    "training servers' push requests, making the parameter servers\n",
    "unavailable. On the other hand, adopting a weak-consistency replication\n",
    "protocol might result in replicas storing inconsistent parameters. To\n",
    "counter this, recent developments have introduced weak-consistency\n",
    "replication protocols like Adam and Ekko that leverage machine learning\n",
    "workload characteristics to reduce the communication cost of\n",
    "synchronizing replicas. For example, Microsoft's Adam protocol\n",
    "introduces a two-phase commit protocol for accelerating parameter\n",
    "synchronization while Ekko features a decentralized algorithm where\n",
    "parameter servers can analyze the model updates based on the gradient\n",
    "magnitude. Ekko further prioritizes the synchronization requests that\n",
    "are more likely to affect the quality of model inference.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}