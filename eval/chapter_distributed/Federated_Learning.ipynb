{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd51ef71",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# Federated Learning\n",
    "\n",
    "Federated Learning is a specialized form of distributed machine learning\n",
    "that enables multiple client devices (such as smartphones and personal\n",
    "computers) to collaboratively train a model without sharing their\n",
    "private datasets. This approach primarily aims to enhance privacy\n",
    "protection for users.\n",
    "\n",
    "In a federated learning system, training data remains on the clients'\n",
    "devices, with only model parameters exchanged among participants. This\n",
    "contrasts with traditional distributed machine learning, where a single\n",
    "entity collects the entire dataset into a data center. For instance, an\n",
    "input method software company might record user input on mobile devices\n",
    "and upload this data to servers for model training. In federated\n",
    "learning, data stays on users' devices, and the model is trained and\n",
    "updated locally, with parameters shared among participants to update the\n",
    "model.\n",
    "\n",
    "Federated learning systems can be classified into two types:\n",
    "cross-device and cross-organizational. The main difference lies in the\n",
    "nature of the clients involved.\n",
    "\n",
    "In cross-device federated learning, the clients are typically personal\n",
    "user devices. These devices often have limited computational\n",
    "capabilities, unstable communication, and may not always be online. On\n",
    "the other hand, in cross-organizational federated learning, clients are\n",
    "usually servers of large institutions like hospitals and banks. These\n",
    "clients, though fewer in number, possess strong computational\n",
    "capabilities and stable network connections.\n",
    "\n",
    "A notable example of federated learning deployment is its optimization\n",
    "for mobile phone input methods, as demonstrated by Google's research.\n",
    "Predicting the user's next input word using machine learning models can\n",
    "significantly enhance user experience. Traditionally, user input content\n",
    "needs to be collected on the service provider's server for training\n",
    "data. However, due to privacy concerns, users may not want their input\n",
    "content collected. Federated learning addresses this by sending only\n",
    "model parameters to user devices. Client programs locally record input\n",
    "data, update model parameters, and then upload the updated parameters\n",
    "back to the server. By aggregating updates from multiple users, the\n",
    "central server can improve the model's accuracy without accessing users'\n",
    "private data.\n",
    "\n",
    "Other examples of federated learning systems are often found in\n",
    "healthcare and financial sectors. For example, in healthcare, multiple\n",
    "hospitals can collaboratively train models through federated learning\n",
    "without sharing patients' raw data, thereby enhancing diagnostic\n",
    "support.\n",
    "\n",
    "## Key Operations in Federated Learning Systems\n",
    "\n",
    "![Architecture of a federated learning system implemented through aparameterserver](../img/ch10/ch10-neo-federated-learning-architecture.pdf)\n",
    ":label:`ch010/ch10-federated-learning-systems`\n",
    "\n",
    "We use an input method's next-word prediction task to illustrate the\n",
    "typical architecture of a federated learning system. As shown in Figure\n",
    "1, there is usually a server and multiple clients. The server can be a\n",
    "cloud server belonging to the input method provider, while the clients\n",
    "run the input method programs on user devices.\n",
    "\n",
    "To train the latest model using user data, the input method provider can\n",
    "initiate a federated learning-based model training session. During this\n",
    "session, they must select a training algorithm, such as FedSGD or\n",
    "FedAvg. For illustration, we will use the widely-adopted FedAvg\n",
    "algorithm defined in\n",
    "Algorithm :numref:`fedavg`. FedAvg primarily has the following steps:\n",
    "\n",
    "1.  Model parameter initialization: In the first step, the server\n",
    "    initializes the model parameters as input parameters for the\n",
    "    federated learning system.\n",
    "\n",
    "2.  Client selection: The system selects a batch of clients from the\n",
    "    user pool based on the following criteria: (i) Devices connected to\n",
    "    a stable local network (e.g., Wi-Fi), (ii) Users not actively using\n",
    "    the device, and (iii) Devices being charged The current model\n",
    "    parameters are then broadcast to these selected clients.\n",
    "\n",
    "3.  Local updates: Clients receive the model parameters and conduct\n",
    "    local model training, such as using the SGD algorithm. Unlike\n",
    "    typical distributed training, federated learning performs multiple\n",
    "    rounds of gradient updates locally to reduce the cost of uploading\n",
    "    parameters each round. After several updates, clients upload their\n",
    "    latest local model parameters back to the server.\n",
    "\n",
    "4.  Global aggregation and update: The server calculates a weighted\n",
    "    average of the received model parameters to obtain the new global\n",
    "    model parameters. This process repeats until the model accuracy\n",
    "    meets the requirements or the loss is sufficiently low.\n",
    "\n",
    "![Federated Averaging (FedAvg)](../img/ch10/algo_fedavg.png)\n",
    ":label:`fedavg`\n",
    "\n",
    "Deploying the FedAvg system in practice presents several challenges.\n",
    "First, due to the lack of low-latency, high-bandwidth network\n",
    "connections between the clients and servers involved in federated\n",
    "learning, it is not feasible to average gradients every round. To\n",
    "address this, practitioners often average model parameters every few\n",
    "rounds instead of averaging gradients every round. Further, the\n",
    "configurations of devices used for model training can vary\n",
    "significantly, leading to differences in the time taken by selected\n",
    "clients to complete training. To address this, practitioners often\n",
    "Select more clients than needed during client selection. The server then\n",
    "aggregates parameters and moves to the next iteration once a sufficient\n",
    "number of clients return model parameters.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}