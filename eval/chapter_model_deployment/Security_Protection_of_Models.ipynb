{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27811fc8",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# Security Protection of Models\n",
    "\n",
    "After training and optimizing models locally, AI service providers\n",
    "deploy the models on third-party platforms (such as mobile devices, edge\n",
    "devices, and cloud servers) to provide inference services. The design\n",
    "and training of the AI models require a large amount of time, data, and\n",
    "computing power. This is why model and service providers protect the\n",
    "intellectual property rights of the models (including model structures\n",
    "and parameters) from being stolen during transfer, storage, and running\n",
    "in the deployment phase.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The security protection of models can be divided into static protection\n",
    "and dynamic protection. Static protection refers to protecting models\n",
    "during transfer and storage. At present, it is widely implemented based\n",
    "on file encryption, in which AI model files are transferred and stored\n",
    "in ciphertext and are decrypted in the memory before being used for\n",
    "inference. However, throughout the inference process, models remain in\n",
    "plaintext in the memory, making it possible for theft. Dynamic\n",
    "protection refers to protecting models during runtime. Dynamic\n",
    "protection methods currently available can be classified into three\n",
    "categories. The first is trusted execution environment-based (TEE-based)\n",
    "protection. TEEs are usually secure zones isolated on trusted hardware,\n",
    "and AI model files are stored and transferred in non-secure zones and\n",
    "running after decryption in the secure zones. Although this method\n",
    "involves only a short inference latency on the CPU, it requires specific\n",
    "trusted hardware, making it difficult to implement. In addition, due to\n",
    "constraints on hardware resources, protecting large-scale deep models is\n",
    "difficult and heterogeneous hardware acceleration is still challenging.\n",
    "The second is a cryptographic computing-based protection, which ensures\n",
    "that models remain in ciphertext during transfer, storage, and running\n",
    "using cryptographic techniques (such as homomorphic encryption and\n",
    "secure multi-party computation). Although this method is free from\n",
    "hardware constraints, it has large computation or communications\n",
    "overheads and cannot protect model structure information. The third is\n",
    "obfuscation-based protection. This method scrambles the computational\n",
    "logic of models with fake nodes, so that attackers cannot understand the\n",
    "models even if they obtain them. Compared with the former two methods,\n",
    "obfuscation-based protection brings a smaller overhead to the\n",
    "performance and neglectable loss of accuracy. Furthermore, it is\n",
    "hardware-agnostic, and can support protection of very large models. We\n",
    "will focus on protection using the obfuscation-based method.\n",
    "\n",
    "## Model Obfuscation\n",
    "\n",
    "Model obfuscation can automatically obfuscate the computational logic of\n",
    "plaintext AI models, preventing attackers from understanding the models\n",
    "even if they obtain them during transfer and storage. In addition,\n",
    "models can run while still being obfuscated, thereby ensuring the\n",
    "confidentiality while they are running. Obfuscation does not affect the\n",
    "inference results and brings only a low performance overhead.\n",
    "\n",
    "![Procedure of modelobfuscation](../img/ch08/model_obfuscate.png)\n",
    ":label:`ch-deploy/model_obfuscate`\n",
    "\n",
    "Figure :numref:`ch-deploy/model_obfuscate` depicts the model obfuscation\n",
    "procedure, which is described as follows.\n",
    "\n",
    "1.  **Interpret the given model into a computational graph:** Based on\n",
    "    the structure of a trained model, interpret the model file into the\n",
    "    graph expression (computational graph) of the model computational\n",
    "    logic for subsequent operations. The resulting computational graph\n",
    "    contains information such as node identifiers, node operator types,\n",
    "    node parameters, and network structures.\n",
    "\n",
    "2.  **Scramble the network structure of the computational graph[^1]:**\n",
    "    Scramble the relationship between nodes in the computational graph\n",
    "    using graph compression, augmentation, and other techniques in order\n",
    "    to conceal the true computational logic. In graph compression, the\n",
    "    key subgraph structure is matched by checking the entire graph.\n",
    "    These subgraphs are compressed and replaced with a single new\n",
    "    computing node. Graph augmentation adds new input/output edges to\n",
    "    the compressed graph in order to further conceal the dependencies\n",
    "    between nodes. An input/output edge comes from or points to an\n",
    "    existing node in the graph, or comes from or points to the new\n",
    "    obfuscation node in this step.\n",
    "\n",
    "3.  **Anonymize nodes in the computational graph:** Traverse the\n",
    "    computational graph processed in Step (2) and select the nodes to be\n",
    "    protected. For a node to be protected, we can replace the node\n",
    "    identifier, operator type, and other attributes that can describe\n",
    "    the computational logic of the model with non-semantic symbols. For\n",
    "    node identifier anonymization, the anonymized node identifier must\n",
    "    be unique in order to distinguish different nodes. For operator type\n",
    "    anonymization, to avoid operator type explosion caused by\n",
    "    large-scale computational graph anonymization, we can divide nodes\n",
    "    with the same operator type into several disjoint sets, and replace\n",
    "    the operator type of nodes in the same set with the same symbol.\n",
    "    Step (5) ensures that the model can be identified and executed after\n",
    "    node anonymization.\n",
    "\n",
    "4.  **Scramble weights of the computational graph:** Add random noise\n",
    "    and mapping functions to the weights to be protected. The random\n",
    "    noise and mapping functions can vary with weights. Step (6) ensures\n",
    "    that the noise of weights does not change the model execution\n",
    "    result. The computational graph processed after Steps (2), (3),\n",
    "    and (4) are then saved as a model file for subsequent operations.\n",
    "\n",
    "5.  **Transform operator interfaces:** Steps (5) and (6) transform\n",
    "    operators to be protected in order to generate candidate obfuscated\n",
    "    operators. An original operator may correspond to multiple\n",
    "    obfuscated operators. The quantity of candidate obfuscated operators\n",
    "    depends on how many sets the nodes are grouped into in Step (3). In\n",
    "    this step, the operator interfaces are transformed based on the\n",
    "    anonymized operator types and operator input/output relationship\n",
    "    obtained after Steps (2), (3), and (4). Such transformation can be\n",
    "    implemented by changing the input, output, or interface name.\n",
    "    Changing the input and output involves modification on the input and\n",
    "    output data, making the form of the obfuscated operator different\n",
    "    from that of the original operator. The added data includes the data\n",
    "    dependency introduced by graph augmentation in Step (2) and the\n",
    "    random noise introduced by weight obfuscation in Step (4). The\n",
    "    operator name is changed to the name of the anonymized operator\n",
    "    obtained in Step (3) to ensure that the model can still be\n",
    "    identified and executed after the nodes are anonymized and that the\n",
    "    operator name does not reveal the computational logic.\n",
    "\n",
    "6.  **Transform the operator implementation:** Transform the operator\n",
    "    code implementation by encrypting strings, adding redundant code,\n",
    "    and employing other code obfuscation techniques in order to keep the\n",
    "    computational logic consistent between the original operator and\n",
    "    obfuscated operator while also making the logic more difficult to\n",
    "    understand. A combination of different code obfuscation techniques\n",
    "    may be applied to different operators in order to realize the code\n",
    "    implementation transformation. In addition to equivalent code\n",
    "    transformation, the obfuscated operators further implement some\n",
    "    additional computational logic. For example, in Step (4), noise has\n",
    "    been added to the weights of an operator. The obfuscated operator\n",
    "    also implements an inverse mapping function of the weight noise,\n",
    "    dynamically eliminating noise in the operator execution process and\n",
    "    ensuring that the computation result is the same as the original\n",
    "    model. The generated obfuscated operators can then be saved as a\n",
    "    library file for subsequent operations.\n",
    "\n",
    "7.  **Deploy the model and operator library:** Deploy the obfuscated\n",
    "    model and corresponding operator library file on the desired device.\n",
    "\n",
    "8.  **Load the obfuscated model:** Parse the obfuscated model file and\n",
    "    obtain the graph expression of the model computational logic, that\n",
    "    is, the obfuscated computational graph obtained after Step (2), (3),\n",
    "    and (4).\n",
    "\n",
    "9.  **Initialize the computational graph:** Initialize the computational\n",
    "    graph to generate an execution task sequence. According to security\n",
    "    configuration options, if runtime model security needs to be\n",
    "    protected, the obfuscated graph should be directly initialized to\n",
    "    generate an execution task sequence. Each compute unit in the\n",
    "    sequence corresponds to execution of one obfuscated operator or\n",
    "    original operator. If security protection is required during only\n",
    "    model transfer and storage, restore the obfuscated graph in the\n",
    "    memory to the source graph, and then initialize the source graph to\n",
    "    generate an execution task sequence. Each unit in the sequence\n",
    "    corresponds to the execution of an original operator. In this way,\n",
    "    performance overheads during inference can be further reduced.\n",
    "\n",
    "10. **Execute inference tasks:** The model executes the compute units\n",
    "    sequentially on the input of the AI application in order to obtain\n",
    "    an inference result. If a compute unit corresponds to an obfuscated\n",
    "    operator, the obfuscated operator library is invoked. Otherwise, the\n",
    "    original operator library is invoked.\n",
    "\n",
    "[^1]: Scrambling refers to adding noise to the computational graph.\n",
    "    Common methods include adding redundant nodes and edges and merging\n",
    "    some subgraphs.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}