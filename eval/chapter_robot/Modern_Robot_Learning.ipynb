{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9bbe791",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# Modern Robot Learning\n",
    "\n",
    "## Overview\n",
    "\n",
    "We human can interact with objects with various shapes, sizes, materials\n",
    "and physics properties. And we have a fantanstic ability to do it under\n",
    "different environment settings: we can avoid potentially dangerous\n",
    "collisions, we can finish a task with a long horizon; and we can learn\n",
    "extremely hard task after practice. However, it still a challenge to\n",
    "teach a machine to have above ability. A key challenge in intelligent\n",
    "robotics is creating robots that are capable of directly interacting\n",
    "with the world around them to achieve their goals. The last decade has\n",
    "seen substantial growth in research on the problem of robot\n",
    "manipulation, which aims to exploit the increasing availability of\n",
    "affordable robot arms and grippers to create robots capable of directly\n",
    "interacting with the world to achieve their goals. Learning will be\n",
    "central to such autonomous systems, as the real world contains too much\n",
    "variation for a robot to expect to have an accurate model of its\n",
    "environment, the objects in it, or the skills required to manipulate\n",
    "them.\n",
    "\n",
    "![An Overview of Common Frameworks for RobotLearning.](../img/ch13/framework.pdf)\n",
    ":label:`robot-framework`\n",
    "\n",
    "## Robot Interaction Environments\n",
    "\n",
    "In the realm of robot learning, the process of acquiring the ability to\n",
    "manipulate objects in real-world settings can be a time-consuming and\n",
    "resource-intensive endeavor. Not only does it demand considerable\n",
    "effort, but it also necessitates substantial hardware investments. To\n",
    "tackle these challenges and expedite the learning process, researchers\n",
    "have turned to data-driven methods that make use of simulation\n",
    "environments. By simulating various scenarios, these environments enable\n",
    "robots to learn and make informed decisions without the need for\n",
    "physically interacting with the real world. In this chapter, we will\n",
    "explore the concept of using simulation environments for robot decision\n",
    "making, highlighting some simulator examples and their key features,\n",
    "while drawing comparisons to the real world and the underlying hardware\n",
    "considerations.\n",
    "\n",
    "### Learning in Simulation Environments: {#learning-in-simulation-environments .unnumbered}\n",
    "\n",
    "Simulators have emerged as indispensable tools for training robots in a\n",
    "controlled and efficient manner. Instead of relying solely on real-world\n",
    "experiences, simulation environments provide a cost-effective means of\n",
    "generating large amounts of training data. This approach not only saves\n",
    "time but also minimizes the risks associated with operating physical\n",
    "robots in potentially hazardous or expensive settings. Furthermore,\n",
    "simulators offer the flexibility to create diverse scenarios and\n",
    "manipulate various environmental parameters, allowing researchers to\n",
    "thoroughly explore different learning strategies and optimize robot\n",
    "decision-making algorithms.\n",
    "\n",
    ":Physics Simulation Libraries and Environments\n",
    "\n",
    "|**Year**   |**Simulator**                         |**Description** |\n",
    "|-----------|--------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "|2012       |MuJoCo [@todorov2012mujoco]           |MuJoCo offers a unique combination of speed, accuracy and modeling power, designed from the ground up for model-based optimization and optimization through contacts. |\n",
    "|2016       |PyBullet [@coumans2016pybullet]       |PyBullet is an easy to use Python module for physics simulation, robotics and deep reinforcement learning based on the Bullet Physics SDK. |\n",
    "|2016       |Unreal CV [@qiu2016unrealcv]          |Unreal CV provides functions for perception, navigation, physical simulations, and learning and evaluation of algorithms. |\n",
    "|2016       |DeepMind Lab [@beattie2016deepmind]   |DeepMind Lab is a first-person 3D game platform designed for research and development of general artificial intelligence and machine learning systems. |\n",
    "|2016       |Habitat [@beattie2016deepmind]        |Habitat-Sim is a flexible, high-performance 3D simulator with configurable agents, sensors, and generic 3D dataset handling. |\n",
    "|2017       |AI2-THOR [@kolve2017ai2]              |AI2-THOR consists of near photo-realistic 3D indoor scenes, enabling research in various domains including deep reinforcement learning and visual question answering. |\n",
    "|2018       |CHALET [@yan2018chalet]               |CHALET includes rooms and house configurations for training and evaluating autonomous agents in a challenging dynamic environment. |\n",
    "|2018       |VirtualHome [@puig2018virtualhome]    |VirtualHome simulator allows the creation of a large activity video dataset with rich ground-truth, enabling training and testing of video understanding models. |\n",
    "|2019       |VRKitchen [@gao2019vrkitchen]         |VRKitchen enables embodied agents to perform complex tasks involving fine-grained object manipulations in a realistic environment, and supports learning from demonstration. |\n",
    "|2020       |SAPIEN [@xiang2020sapien]             |SAPIEN is a realistic and physics-rich simulated environment that hosts a large-scale set of articulated objects, enabling various robotic vision and interaction tasks. |\n",
    "|2020       |ThreeDWorld [@gan2020threedworld]     |ThreeDWorld is a platform for interactive multi-modal physical simulation, supporting real-time near-photo-realistic image rendering, high-fidelity audio rendering, and more. |\n",
    "|2021       |Brax [@freeman2021brax]               |Brax is an open-source library for rigid body simulation with a focus on performance and parallelism on accelerators, written in JAX. |\n",
    "|2021       |iGibson2.0 [@li2021igibson]           |iGibson 2.0 supports object states, predicate logic functions, and can sample valid physical states based on logic states. |\n",
    "|2021       |Issac Gym [@makoviychuk2021isaac]     |Isaac Gym offers a high performance learning platform to train policies for a wide variety of robotics tasks directly on GPU. |\n",
    ":label:`simulations`\n",
    "\n",
    "As shown in Table :numref:`simulations`, there are several simulator examples used\n",
    "in the field.\n",
    "\n",
    "### Comparing Simulators to the Real World: {#comparing-simulators-to-the-real-world .unnumbered}\n",
    "\n",
    "While simulation environments offer numerous advantages, it is essential\n",
    "to recognize the differences between these virtual worlds and the real\n",
    "world. One crucial distinction is the potential discrepancy in physics\n",
    "and dynamics modeling. Simulators often approximate physical\n",
    "interactions, which may deviate from the intricacies and complexities of\n",
    "the actual physical systems. Researchers must be cognizant of these\n",
    "limitations and carefully validate their learned policies in real-world\n",
    "scenarios to ensure robustness and generalizability.\n",
    "\n",
    "Another consideration is the sensory input. In simulation, sensors can\n",
    "provide perfect, noise-free data, whereas real-world sensors are prone\n",
    "to noise, calibration issues, and limited field of view. Accounting for\n",
    "these discrepancies during the learning process and applying appropriate\n",
    "techniques, such as sensor noise injection or domain adaptation, is\n",
    "crucial for achieving successful transfer of learned policies from\n",
    "simulation to reality.\n",
    "\n",
    "![Robot manipulation environments in real\n",
    "world [@geng2022end].](../img/ch13/realworld.pdf)\n",
    "\n",
    "### Hardware Considerations:\n",
    ":label:`hardware-considerations`\n",
    "\n",
    "While simulation environments alleviate the need for expensive hardware\n",
    "setups, certain hardware-related aspects should not be overlooked. To\n",
    "accurately simulate robot behaviors, it is necessary to employ hardware\n",
    "models and kinematic representations that closely resemble the physical\n",
    "robots being studied. Additionally, to ensure efficient and real-time\n",
    "simulation, high-performance computing resources may be required,\n",
    "especially when dealing with complex scenarios or large-scale\n",
    "simulations.\n",
    "\n",
    "### Conclusion:\n",
    ":label:`conclusion`\n",
    "\n",
    "Simulation environments have become invaluable tools for training robots\n",
    "and enabling efficient decision making. By leveraging these virtual\n",
    "worlds, researchers can expedite the learning process while minimizing\n",
    "the costs and risks associated with real-world experimentation. However,\n",
    "it is important to acknowledge the limitations of simulations and the\n",
    "challenges in transferring learned policies to physical systems. Through\n",
    "a combination of careful validation, sensor calibration, and hardware\n",
    "modeling, the gap between simulation and reality can be bridged, paving\n",
    "the way for robust and reliable robot decision-making capabilities in\n",
    "real-world settings.\n",
    "\n",
    "## Robot Skill Learning\n",
    "\n",
    "### Perception\n",
    ":label:`perception`\n",
    "\n",
    "In the fascinating realm of robotics, perception plays a crucial role in\n",
    "enabling robots to interact with and understand the world around them.\n",
    "Just like humans rely on their senses to gather information, robots\n",
    "employ various sensing modalities to perceive and make sense of their\n",
    "environment. This chapter delves into the realm of robot perception,\n",
    "focusing on the integration of multiple sensing modalities and their\n",
    "significance in enhancing a robot's understanding of its surroundings.\n",
    "We will explore the diverse range of sensing modalities available to\n",
    "robots and their unique capabilities in perception.\n",
    "\n",
    "**Visual Perception:** Visual perception is one of the primary sensing\n",
    "modalities for robots, mimicking human vision. Cameras and image sensors\n",
    "capture visual data, allowing robots to perceive objects, scenes, and\n",
    "spatial information. This section discusses the role of computer vision\n",
    "techniques, such as image processing, object recognition, and depth\n",
    "estimation, in enabling robots to interpret visual data and extract\n",
    "meaningful information.\n",
    "\n",
    "**Tactile Perception:** Tactile perception focuses on a robot's ability\n",
    "to sense and interpret physical contact with objects and surfaces.\n",
    "Tactile sensors embedded in robotic fingers or hands provide information\n",
    "about texture, shape, hardness, and temperature. This section explores\n",
    "the integration of tactile sensors and their application in object\n",
    "manipulation, grasping, and fine motor control, enabling robots to\n",
    "interact with the physical world in a more human-like manner.\n",
    "\n",
    "**Auditory Perception:** Sound and auditory cues are valuable sources of\n",
    "information for robots. By integrating microphones or specialized\n",
    "auditory sensors, robots can perceive and analyze audio signals, such as\n",
    "speech, environmental sounds, and localization cues. This section\n",
    "discusses the role of auditory perception in tasks like speech\n",
    "recognition, sound source localization, and human-robot interaction,\n",
    "highlighting the importance of audio-based information for comprehensive\n",
    "robot perception.\n",
    "\n",
    "**Range Sensing:** Range sensing modalities, such as LiDAR (Light\n",
    "Detection and Ranging) and depth cameras, provide robots with depth\n",
    "information about their surroundings. By emitting and measuring the\n",
    "time-of-flight or structured light patterns, robots can create detailed\n",
    "3D representations of the environment. This section explores the\n",
    "capabilities of range sensing modalities in object detection,\n",
    "simultaneous localization and mapping (SLAM), and navigation in dynamic\n",
    "environments.\n",
    "\n",
    "**Environmental Sensing:** Robots can also perceive the environment\n",
    "using various sensors that capture information beyond the range of human\n",
    "senses. This section covers sensing modalities like infrared sensors,\n",
    "gas sensors, and environmental monitoring devices. These sensors enable\n",
    "robots to detect temperature, gas concentrations, humidity, and other\n",
    "environmental factors, making them suitable for applications in\n",
    "environmental monitoring, disaster response, and industrial settings.\n",
    "\n",
    "**Fusion and Integration of Sensing Modalities:** To achieve a more\n",
    "comprehensive understanding of the environment, robots often integrate\n",
    "multiple sensing modalities. This section explores the challenges and\n",
    "techniques involved in fusing data from different sensors, such as\n",
    "sensor calibration, data alignment, and sensor fusion algorithms. It\n",
    "also discusses the benefits of sensor fusion in improving perception\n",
    "accuracy, robustness, and adaptability in real-world scenarios.\n",
    "\n",
    "**Conclusion:** Robot perception is a fascinating field that encompasses\n",
    "multiple sensing modalities, each contributing to a robot's ability to\n",
    "perceive and understand its surroundings. By integrating visual,\n",
    "tactile, auditory, range, and environmental sensing, robots can create a\n",
    "rich representation of the world. This chapter provided an overview of\n",
    "different sensing modalities, highlighting their significance in\n",
    "enabling robots to navigate, interact, and make informed decisions in\n",
    "complex environments. By harnessing the power of diverse sensing\n",
    "modalities, robots continue to advance in their ability to perceive,\n",
    "learn, and adapt, bringing us closer to a world where intelligent\n",
    "machines coexist seamlessly with humans.\n",
    "\n",
    "### Decision\n",
    ":numref:`decision`\n",
    "\n",
    "In the field of robotics, decision-making plays a vital role in enabling\n",
    "robots to interact intelligently with their environment. This chapter\n",
    "explores various approaches to robot decision-making, including\n",
    "heuristic policy, reinforcement learning, affordance learning, and\n",
    "knowledge extraction from large models. By understanding these\n",
    "techniques, we can gain insights into how robots can make informed and\n",
    "adaptive decisions.\n",
    "\n",
    "**Heuristic Policy:** Heuristic policy refers to a decision-making\n",
    "strategy based on predefined rules or heuristics. These rules are\n",
    "typically crafted by human experts and capture domain-specific knowledge\n",
    "to guide the robot's actions. Heuristic policies provide a fast and\n",
    "reliable way for robots to make decisions in certain contexts, but they\n",
    "may lack adaptability and struggle in complex and dynamic environments.\n",
    "Nevertheless, they can serve as a useful starting point for robot\n",
    "decision-making before more sophisticated techniques are employed.\n",
    "\n",
    "**Reinforcement Learning:** Reinforcement learning (RL) is a powerful\n",
    "approach that enables robots to learn decision-making policies through\n",
    "interactions with the environment [@chen2022towards]. In RL, a robot\n",
    "learns to maximize a numerical reward signal by taking actions and\n",
    "observing their outcomes. By exploring different actions and receiving\n",
    "feedback in the form of rewards or penalties, the robot gradually\n",
    "discovers the optimal policy for decision-making.\n",
    "\n",
    "Reinforcement learning consists of the following key elements: a. Agent:\n",
    "The robot or decision-making entity. b. Environment: The external world\n",
    "or simulation in which the agent interacts. c. State: The representation\n",
    "of the current situation or context. d. Action: The choices available to\n",
    "the agent. e. Reward: The feedback signal indicating the desirability of\n",
    "an action in a given state.\n",
    "\n",
    "**Affordance Learning:**\n",
    "\n",
    "![Affordance visualization results in robot manipulation\n",
    "tasks [@geng2022end].](../img/ch13/affordance.pdf)\n",
    "\n",
    "Affordance learning focuses on understanding the action possibilities\n",
    "that the environment offers to a\n",
    "robot [@mo2021where2act; @wu2021vat; @zhao2022dualafford; @wang2022adaafford; @geng2022end].\n",
    "It involves perceiving and extracting relevant information about the\n",
    "affordances, which are the potential actions or interactions that an\n",
    "object or a scene can afford. By recognizing and understanding\n",
    "affordances, robots can make more informed decisions about their\n",
    "actions. Affordance learning includes the following steps: a.\n",
    "Perception: Sensing the environment through various sensors (e.g.,\n",
    "cameras, depth sensors) to capture relevant data. b. Feature Extraction:\n",
    "Extracting meaningful features from the sensory data to represent the\n",
    "objects or scenes. c. Affordance Recognition: Identifying and\n",
    "categorizing the potential actions or interactions that the objects or\n",
    "scenes afford. d. Decision-Making: Utilizing the recognized affordances\n",
    "to guide the robot's decision-making process.\n",
    "\n",
    "**Knowledge Extraction from Large Models:** With the advancement of deep\n",
    "learning and large-scale language models, extracting knowledge from\n",
    "these models has become increasingly valuable for decision-making in\n",
    "robotics. These models are trained on vast amounts of data and capture\n",
    "intricate patterns and relationships. By leveraging this knowledge,\n",
    "robots can benefit from the collective intelligence captured in these\n",
    "models [@brohan2023can; @liang2023cod; @huang2023visual]. Typically,\n",
    "knowledge extraction from large models involves the following steps: a.\n",
    "Model Interpretability: Understanding how the model processes input data\n",
    "and generates predictions or decisions. b. Feature Extraction:\n",
    "Extracting relevant features or representations from the model that\n",
    "capture the essential information for decision-making. c. Transfer\n",
    "Learning: Transferring knowledge from pre-trained models to improve\n",
    "decision-making in specific robotic tasks. d. Decision Fusion: Combining\n",
    "the knowledge extracted from the large models with other decision-making\n",
    "techniques to make more informed and robust decisions.\n",
    "\n",
    "Robot decision-making is a critical aspect of enabling robots to\n",
    "interact intelligently with their environment. Heuristic policies\n",
    "provide initial guidelines, while reinforcement learning allows robots\n",
    "to learn optimal decision-making policies through interaction with the\n",
    "environment. Affordance learning helps robots recognize and understand\n",
    "the potential actions in their surroundings. Finally, knowledge\n",
    "extraction from large models leverages the wealth of information\n",
    "captured in these models to enhance decision-making capabilities. By\n",
    "integrating these techniques, robots can make more adaptive,\n",
    "context-aware, and intelligent decisions in various scenarios, leading\n",
    "to significant advancements in the field of robot learning.\n",
    "\n",
    "## Deployment in real environments\n",
    "\n",
    "In the field of robotics, the ability of a robot to make intelligent\n",
    "decisions is crucial for its effective interaction with the real world.\n",
    "Over the years, significant progress has been made in developing\n",
    "algorithms and techniques to enable robots to learn and make decisions\n",
    "directly in real environments. In this chapter, we will explore some key\n",
    "topics related to robot decision-making, including learning directly in\n",
    "real environments, the Sim2Real approach, real-world feedback, learning\n",
    "from real-world demonstrations, and the concept of Teacher-Student\n",
    "Distillation.\n",
    "\n",
    "### Learning Directly in Real Environments\n",
    ":label:`learning-directly-in-real-environments`\n",
    "\n",
    "One of the fundamental approaches to robot decision-making involves\n",
    "learning directly in real environments. Traditional methods often rely\n",
    "on simulations or simplified scenarios, but learning in real-world\n",
    "conditions provides robots with a more accurate understanding of the\n",
    "complexities and uncertainties they encounter. This approach leverages\n",
    "techniques such as reinforcement learning, where robots learn through\n",
    "trial and error, optimizing their decision-making policies based on\n",
    "feedback received from the environment.\n",
    "\n",
    "### Sim2Real and Real-World Feedback\n",
    ":label:`sim2real-and-real-world-feedback`\n",
    "\n",
    "While learning in real environments is desirable, it can be challenging\n",
    "due to constraints such as safety concerns, cost, and limited access to\n",
    "real-world scenarios. The Sim2Real approach [@hofer2021sim2real]\n",
    "addresses these challenges by training robots initially in simulation\n",
    "environments, which are cheaper, safer, and provide more extensive data.\n",
    "However, to ensure effective decision-making in the real world, the\n",
    "trained policies need to be transferred and adapted to the physical\n",
    "domain. Real-world feedback mechanisms, such as domain adaptation\n",
    "techniques and reinforcement learning with fine-tuning, play a vital\n",
    "role in this process by bridging the simulation-to-reality gap.\n",
    "\n",
    "### Learning from Real-World Demonstrations\n",
    ":label:`learning-from-real-world-demonstrations`\n",
    "\n",
    "Learning from real-world demonstrations is another powerful paradigm for\n",
    "robot decision-making. By observing and imitating human or expert\n",
    "demonstrations, robots can acquire valuable knowledge about appropriate\n",
    "decision-making strategies. This approach often involves techniques such\n",
    "as imitation learning or inverse reinforcement learning, where robots\n",
    "learn from the actions and decisions of skilled individuals. By\n",
    "generalizing from a limited number of demonstrations, robots can learn\n",
    "to make intelligent decisions in similar contexts.\n",
    "\n",
    "### Teacher-Student Distillation\n",
    ":label:`teacher-student-distillation`\n",
    "\n",
    "Teacher-Student Distillation is a methodology that leverages the\n",
    "knowledge of a more capable teacher model to enhance the decision-making\n",
    "capabilities of a less experienced student\n",
    "model [@gou2021knowledge; @hussein2017imitation; @ross2011reduction; @geng2023partmanip].\n",
    "In the context of robot learning, this approach involves training a\n",
    "high-performing policy (the teacher) and using its expertise to guide\n",
    "and improve the learning process of a less optimal policy (the student).\n",
    "This technique can be particularly useful in scenarios where direct\n",
    "reinforcement learning is challenging or time-consuming. The teacher\n",
    "model can provide valuable feedback and constraints to facilitate\n",
    "efficient decision-making in complex real-world environments.\n",
    "\n",
    "### Conclusion\n",
    ":label:`conclusion-1`\n",
    "\n",
    "Robot decision-making in real environments is a multifaceted field that\n",
    "encompasses various approaches and techniques. Learning directly in real\n",
    "environments, leveraging Sim2Real methods, incorporating real-world\n",
    "feedback, learning from demonstrations, and employing Teacher-Student\n",
    "Distillation are all essential aspects of advancing the capabilities of\n",
    "robots. As researchers and practitioners, we continue to explore these\n",
    "topics to enhance robot learning and decision-making, enabling robots to\n",
    "operate effectively and intelligently in diverse real-world settings.\n",
    "Teacher-Student Distillation\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}