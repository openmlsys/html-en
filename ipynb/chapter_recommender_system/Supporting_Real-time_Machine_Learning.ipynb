{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ab0bbcc",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# Supporting Real-time Machine Learning\n",
    "\n",
    "The landscape of contemporary recommender systems has seen a growing\n",
    "trend in the adoption of a real-time machine learning architecture.\n",
    "However, realizing the full potential of such a architecture poses\n",
    "considerable challenges.\n",
    "\n",
    "Recommender systems may aim to enhance the quality of their suggestions\n",
    "by managing an extensive array of parameters. These parameters are often\n",
    "replicated across multiple data centers to minimize access latency. Yet,\n",
    "the ongoing updating of these parameters by machine learning models can\n",
    "generate a significant volume of synchronization traffic. In essence,\n",
    "any update to a \\\"leader\\\" parameter replica necessitates timely\n",
    "reflection in all corresponding \\\"follower\\\" replicas.\n",
    "\n",
    "## System Challenges\n",
    "\n",
    "Transitioning from offline model training to the more dynamic real-time\n",
    "(or online) model training in a recommender system presents several\n",
    "system-related challenges:\n",
    "\n",
    "### Needs for Synchronizing Massive Replicas\n",
    "\n",
    "In a recommender system, model parameters are typically replicated\n",
    "across multiple servers. These replicas exist on servers within a single\n",
    "data center and can collaboratively address parameter queries. This\n",
    "approach enhances query throughput by distributing the load evenly among\n",
    "the servers. In addition, replicas are also located in geographically\n",
    "distributed data centers. This strategic placement not only improves the\n",
    "availability of the model parameters, but also the locality at which\n",
    "these replicas can be accessed. Consequently, a single model parameter\n",
    "may have numerous replicas (for instance, between tens and hundreds) in\n",
    "a distributed environment.\n",
    "\n",
    "In the context of real-time machine learning, the training servers need\n",
    "to frequently update the primary (leader) replica of a parameter. The\n",
    "primary replica must coordinate with all other secondary (follower)\n",
    "replicas to ensure consistency. Coordinating such a vast number of\n",
    "replicas often surpasses the capabilities of traditional synchronization\n",
    "protocols, which are typically designed for syncing smaller sets of file\n",
    "replicas across different devices.\n",
    "\n",
    "### Excessive Network Traffic\n",
    "\n",
    "The training data center continuously collects new training samples and\n",
    "instantaneously uses these samples to compute gradients for model\n",
    "parameter updates. These updates must then be transferred over a network\n",
    "comprising both a Local Area Network (LAN) and a Wide Area Network\n",
    "(WAN). The LAN connects the servers within a data center, while the WAN\n",
    "interlinks multiple data centers.\n",
    "\n",
    "Empirical system traces have revealed that the model update traffic can\n",
    "reach up to hundreds of gigabytes per second. This volume of traffic is\n",
    "significantly greater than what a typical LAN or WAN can handle. On\n",
    "average, a LAN can deliver an aggregated throughput ranging from 100 to\n",
    "1000 Gbps, while a WAN can provide a bandwidth ranging from 10 to 100\n",
    "Gbps.\n",
    "\n",
    "### Lack of Model Validation\n",
    "\n",
    "In the context of real-time machine learning, the gradient of a\n",
    "parameter (or an updated version of this parameter) is immediately sent\n",
    "to all replicas. This gradient however could adversely affect the\n",
    "recommendation quality. The underlying reason for this is the\n",
    "architectural design of real-time machine learning systems, which\n",
    "permits the training server to calculate gradients based on a small\n",
    "batch of real-time samples. These samples, collected in an online\n",
    "environment, can potentially be biased or malicious.\n",
    "\n",
    "Traditionally, the negative impacts of these gradients are mitigated\n",
    "through extended training periods, with only the checkpoints that pass\n",
    "validation being disseminated to replicas. However, real-time machine\n",
    "learning does not allow for such offline validation. As a consequence,\n",
    "there is an urgent need to devise new strategies that protect the\n",
    "recommendation system from being negatively impacted by detrimental\n",
    "gradients.\n",
    "\n",
    "## Application-Specific Synchronization Protocols\n",
    "\n",
    "To mitigate the challenge of leader bottlenecks during synchronization\n",
    "of replicas, designers of distributed machine learning systems have\n",
    "turned to application-specific synchronization protocols. These\n",
    "protocols are devised to capitalize on the data characteristics unique\n",
    "to machine learning applications, with the aim of expediting the\n",
    "synchronization process. For instance, Microsoft's Adam utilizes a\n",
    "customized two-phase commit protocol in its parameter server system for\n",
    "machine learning model replicas. Moreover, some parameter servers are\n",
    "designed to skip synchronization requests when the gradient magnitude is\n",
    "relatively small, implying that a model update is unlikely to\n",
    "drastically affect the inference outcomes of a machine learning model.\n",
    "\n",
    "Despite their general efficacy, these protocols can encounter\n",
    "difficulties in real-world recommender systems due to a couple of\n",
    "factors. Firstly, the requirement of a leader to orchestrate replicas in\n",
    "these parameter servers can become a limiting factor, particularly when\n",
    "there are hundreds of replicas to manage. Secondly, the leader replica's\n",
    "dependence on high-speed networks to facilitate low latency\n",
    "communication with follower replicas can be problematic, as these\n",
    "high-speed networks are not always readily available on a wide area\n",
    "network.\n",
    "\n",
    "Recently, practitioners in the field of recommender systems have been\n",
    "exploring the potential of decentralized synchronization protocols. One\n",
    "noteworthy example is the Ekko system, which expands on traditional\n",
    "peer-to-peer synchronization protocol to effectively manage the vast\n",
    "number of synchronization requests in a recommender system.\n",
    "\n",
    "To demonstrate how a recommender system can utilize the data\n",
    "characteristics of machine learning applications to accelerate\n",
    "synchronization, we'll examine Ekko. Figure\n",
    ":numref:`P2P replication` depicts Ekko's peer-to-peer\n",
    "architecture where replicas can be synchronized among decentralized\n",
    "parameter servers.\n",
    "\n",
    "![Example of decentralized synchronization protocols for parameterservers](../img/ch_recommender/p2p_replication.png)\n",
    ":label:`P2P replication`\n",
    "\n",
    "To execute the peer-to-peer synchronization algorithm, Ekko first\n",
    "attributes a version to each parameter (each key-value pair) by using\n",
    "the established version vector algorithm Â . Every version records the\n",
    "time and location of a parameter's update. Moreover, Ekko establishes a\n",
    "version vector (also referred to as knowledge) within each shard to\n",
    "document all known versions of the shard. By comparing the version\n",
    "number with the version vector, a parameter server can retrieve the\n",
    "updated parameter state from its peers without needing to transmit the\n",
    "parameters. For a more detailed understanding of the version vector\n",
    "algorithm, please refer to the original paper.\n",
    "\n",
    "However, Ekko system researchers have discovered that even with the\n",
    "version vector algorithm, identifying updated parameters amongst a large\n",
    "number of model parameters remains a time-consuming task. To hasten the\n",
    "process of locating updated parameters, Ekko harnesses two key\n",
    "characteristics of recommendation models:\n",
    "\n",
    "1.  **Update Sparsity:** While embedding tables in a model may span\n",
    "    several hundred gigabytes or even several terabytes, the training\n",
    "    server only updates the embedding items included in the current\n",
    "    batch at any given time. This is because model training generally\n",
    "    happens in small batches. From a global perspective, the states of\n",
    "    only a small fraction of parameters within the embedding tables are\n",
    "    updated over a certain time period.\n",
    "\n",
    "2.  **Time Locality:** In a recommender system, model updates aren't\n",
    "    uniformly distributed across all parameters. Embedding items\n",
    "    corresponding to popular items and active users undergo frequent\n",
    "    updates within a specified period of time, whereas those related to\n",
    "    less popular items and inactive users may not be updated at all.\n",
    "\n",
    "Based on these two characteristics, the cornerstone of Ekko's comparison\n",
    "acceleration approach is to circumvent time wasted on comparing versions\n",
    "of parameters that remain unchanged.\n",
    "\n",
    "Within the Ekko system, a *model update cache* is developed in each\n",
    "shard to store the pointers of parameters that have recently been\n",
    "updated. Suppose parameter server A is trying to pull model updates from\n",
    "parameter server B. If parameter server A already has all model updates\n",
    "that parameter server B has not cached, server A can obtain all unknown\n",
    "model updates by simply comparing the parameters stored in the cache of\n",
    "parameter server B. This is all that's needed to ensure server A is up\n",
    "to date.\n",
    "\n",
    "## Application-Aware Model Update Scheduling\n",
    "\n",
    "When dealing with limited bandwidth for model update transfer, designers\n",
    "of distributed machine learning systems often consider the effects of\n",
    "these updates on their applications. The fundamental intuition is that\n",
    "not all model updates exert an equal influence on the service quality of\n",
    "an application. Typically, this quality is assessed in terms of\n",
    "service-level objectives (SLOs), such as latency, recommendation\n",
    "accuracy, user engagement metrics, among others.\n",
    "\n",
    "Various protocols have been developed to prioritize the transmission of\n",
    "model updates over congested networks, based on the impact of these\n",
    "updates on the SLOs. The Ekko system serves as a representative example\n",
    "for illustrating this approach. Typically, three metrics are considered:\n",
    "\n",
    "1.  **Update Freshness:** If the embedding tables of the recommendation\n",
    "    model lack embedding items corresponding to new users or items,\n",
    "    these users or items cannot reap the benefits of the high SLOs\n",
    "    provided by the recommendation model. To counter this, we can assign\n",
    "    the highest priority to newly added embedding items, ensuring that\n",
    "    they are disseminated to all inference service clusters as swiftly\n",
    "    as possible.\n",
    "\n",
    "2.  **Update Significance:** Numerous studies have demonstrated that\n",
    "    model updates with larger gradients considerably impact model\n",
    "    accuracy. Consequently, we can assign varying priorities to\n",
    "    different model updates based on their amplitude. [^1]\n",
    "\n",
    "3.  **Model Importance:** In online services involving multiple models,\n",
    "    each model attracts different volumes of inference traffic.\n",
    "    Therefore, during network congestion, we can give precedence to the\n",
    "    update of models that garner the most traffic.\n",
    "\n",
    "These aforementioned application-level metrics need to be consolidated\n",
    "to effectively guide the scheduling of model updates. We demonstrate\n",
    "this concept using Figure\n",
    ":numref:`model update scheduler`, a model update scheduler\n",
    "implemented in the Ekko system. In this system, the total priority for\n",
    "each model update is computed and then compared with the k-th\n",
    "percentile. If the total priority exceeds the kth percentile, it is\n",
    "considered high priority; otherwise, it is deemed low priority. The\n",
    "value of *k* is user-defined, and the kth percentile is estimated using\n",
    "an existing algorithm based on historical priority data.\n",
    "\n",
    "![Application-aware model update scheduler](../img/ch_recommender/update_scheduler.png)\n",
    ":label:`model update scheduler`\n",
    "\n",
    "## Online Model State Management\n",
    "\n",
    "In the context of real-time machine learning, it's crucial to have\n",
    "mechanisms in place that can continuously monitor the performance of a\n",
    "recommendation model and quickly revert this model to a previous state\n",
    "if any performance degradation is detected. We demonstrate how this can\n",
    "be implemented using the Ekko system.\n",
    "\n",
    "The key design principle involves setting up a group of baseline models\n",
    "and diverting a small amount of the requests (or traffic) from inference\n",
    "requests to these baseline models. This strategy allows the collection\n",
    "of SLO-related metrics from the baseline models.\n",
    "\n",
    "As depicted in Figure :numref:`model state manager`, the time series anomaly detection\n",
    "algorithm in the inference model state manager persistently monitors the\n",
    "SLOs of both baseline and online models. The model state, which could be\n",
    "healthy, uncertain, or corrupted, is maintained by the replicated state\n",
    "machine.\n",
    "\n",
    "If an online model is found to be in a corrupted state, the traffic for\n",
    "this model is redirected to another model in a healthy state. The\n",
    "corrupted model is then rolled back to a previous healthy state before\n",
    "being reintroduced online.\n",
    "\n",
    "![Online Model StateManagement](../img/ch_recommender/state_manager.png)\n",
    ":label:`model state manager`\n",
    "\n",
    "[^1]: The update amplitude could either be the gradient itself or the\n",
    "    gradient multiplied by the learning rate, contingent on the model\n",
    "    training mode.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}