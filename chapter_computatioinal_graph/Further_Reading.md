# Further Reading

1.  Computational graph technology is fundamentally important to major
    machine learning frameworks. For the design details of major machine
    learning frameworks, see *TensorFlow: Large-Scale Machine Learning
    on Heterogeneous Distributed Systems*[^1], and *Pytorch: An
    Imperative Style, High-Performance Deep Learning Library*.

2.  Out-of-graph control flows are created using the frontend language,
    which are easy to grasp for most programmers. However, implementing
    control flows using the in-graph approach could be challenging. For
    more on this topic, see *Implementation of Control Flow in
    TensorFlow*[^2].

3.  For the design and practices of dynamic and static graphs, see
    *TensorFlow Eager: A Multi-Stage, Python-Embedded DSL for Machine
    Learning*[^3], Eager Execution: An imperative, define-by-run
    interface to TensorFlow[^4], Introduction to graphs and
    tf.function[^5], and MindSpore Computational Graph[^6].

[^1]: <https://arxiv.org/pdf/1603.04467.pdf>

[^2]: <http://download.tensorflow.org/paper/white_paper_tf_control_flow_implementation_2017_11_1.pdf>

[^3]: <https://arxiv.org/pdf/1903.01855.pdf>

[^4]: <https://ai.googleblog.com/2017/10/eager-execution-imperative-define-by.html>

[^5]: <https://www.tensorflow.org/guide/intro_to_graphs>

[^6]: <https://www.mindspore.cn/tutorials/en/master/advanced/compute_graph.html>
