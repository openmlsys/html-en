
Chapter Summary
===============

1. Hardware accelerators offer various types of on-chip caches and
   computational units, enhancing the performance of deep learning
   computational tasks.

2. To fully exploit the performance potential of hardware accelerators,
   itâ€™s necessary to implement programmable hardware accelerators,
   bringing architectural innovation.

3. To balance computational efficiency and usability, the programming
   methods for hardware accelerators range from high-level computation
   operators to harnessing the primitives associated with hardware
   units, and to using low-level assembly languages.

4. A variety of methods are crucial to optimize accelerator performance,
   which include enhancing arithmetic intensity, caching data in shared
   memory, and concealing data store/load latency.
