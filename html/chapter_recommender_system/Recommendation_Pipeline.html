<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    
    <title>11.3. Recommendation Pipeline &#8212; Machine Learning Systems: Design and Implementation 1.0.0 documentation</title>

    <link rel="stylesheet" href="../_static/material-design-lite-1.3.0/material.blue-deep_orange.min.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx_materialdesign_theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fontawesome/all.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fonts.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/basic.css" />
    <link rel="stylesheet" type="text/css" href="../_static/d2l.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/d2l.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="11.4. Model Update" href="Model_Update.html" />
    <link rel="prev" title="11.2. System Components" href="System_Components.html" /> 
  </head>
<body>
    <div class="mdl-layout mdl-js-layout mdl-layout--fixed-header mdl-layout--fixed-drawer"><header class="mdl-layout__header mdl-layout__header--waterfall ">
    <div class="mdl-layout__header-row">
        
        <nav class="mdl-navigation breadcrumb">
            <a class="mdl-navigation__link" href="index.html"><span class="section-number">11. </span>Recommender System</a><i class="material-icons">navigate_next</i>
            <a class="mdl-navigation__link is-active"><span class="section-number">11.3. </span>Recommendation Pipeline</a>
        </nav>
        <div class="mdl-layout-spacer"></div>
        <nav class="mdl-navigation">
        
<form class="form-inline pull-sm-right" action="../search.html" method="get">
      <div class="mdl-textfield mdl-js-textfield mdl-textfield--expandable mdl-textfield--floating-label mdl-textfield--align-right">
        <label id="quick-search-icon" class="mdl-button mdl-js-button mdl-button--icon"  for="waterfall-exp">
          <i class="material-icons">search</i>
        </label>
        <div class="mdl-textfield__expandable-holder">
          <input class="mdl-textfield__input" type="text" name="q"  id="waterfall-exp" placeholder="Search" />
          <input type="hidden" name="check_keywords" value="yes" />
          <input type="hidden" name="area" value="default" />
        </div>
      </div>
      <div class="mdl-tooltip" data-mdl-for="quick-search-icon">
      Quick search
      </div>
</form>
        
<a id="button-show-source"
    class="mdl-button mdl-js-button mdl-button--icon"
    href="../_sources/chapter_recommender_system/Recommendation_Pipeline.rst.txt" rel="nofollow">
  <i class="material-icons">code</i>
</a>
<div class="mdl-tooltip" data-mdl-for="button-show-source">
Show Source
</div>
        </nav>
    </div>
    <div class="mdl-layout__header-row header-links">
      <div class="mdl-layout-spacer"></div>
      <nav class="mdl-navigation">
          
              <a  class="mdl-navigation__link" href="https://github.com/openmlsys/openmlsys-en">
                  <i class="fab fa-github"></i>
                  GitHub
              </a>
          
              <a  class="mdl-navigation__link" href="https://openmlsys.github.io/">
                  <i class="fas fa-external-link-alt"></i>
                  中文版
              </a>
      </nav>
    </div>
</header><header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <img class="logo" src="../_static/logo-with-text.png" alt="Machine Learning Systems: Design and Implementation"/>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../chapter_preface/index.html">1. Preface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_introduction/index.html">2. Introduction</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/Machine_Learning_Applications.html">2.1. Machine Learning Applications</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/Design_Objectives_of_Machine_Learning_Frameworks.html">2.2. Design Objectives of Machine Learning Frameworks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/Machine_Learning_Framework_Architecture.html">2.3. Machine Learning Framework Architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/Application_Scenarios_of_Machine_Learning_Systems.html">2.4. Application Scenarios of Machine Learning Systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/Book_Organization_and_Intended_Audience.html">2.5. Book Organization and Intended Audience</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preface_basic/index.html">3. Part I Framework Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_programming_model/index.html">4. Programming Model</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_model/Overview.html">4.1. Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_model/Machine_Learning_Workflow.html">4.2. Machine Learning Workflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_model/Neural_Network_Programming.html">4.3. Neural Network Programming</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_model/Functional_Programming.html">4.4. Functional Programming</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_model/Bridging_Python_and_C_C%2B%2B_Functions.html">4.5. Bridging Python and C/C++ Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_model/Chapter_Summary.html">4.6. Chapter Summary</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_compiler_frontend/index.html">5. AI Compiler Frontend</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_frontend/Overview_of_AI_Compilers.html">5.1. Overview of AI Compilers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_frontend/Overview_of_AI_Compiler_Frontends.html">5.2. Overview of AI Compiler Frontends</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_frontend/Intermediate_Representation.html">5.3. Intermediate Representation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_frontend/Automatic_Differentiation.html">5.4. Automatic Differentiation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_frontend/Type_Systems_and_Static_Analysis.html">5.5. Type Systems and Static Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_frontend/Frontend_Compilation_Optimization.html">5.6. Frontend Compilation Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_frontend/Chapter_Summary.html">5.7. Chapter Summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_frontend/Further_Reading.html">5.8. Further Reading</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_compiler_backend/index.html">6. AI Compiler Backend</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_backend/Overview.html">6.1. Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_backend/Graph_Optimization.html">6.2. Graph Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_backend/Operator_Selection.html">6.3. Operator Selection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_backend/Memory_Allocation.html">6.4. Memory Allocation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_backend/Operator_Compiler.html">6.5. Operator Compiler</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_backend/Chapter_Summary.html">6.6. Chapter Summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_backend/Further_Reading.html">6.7. Further Reading</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_accelerator/index.html">7. Hardware Accelerator</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_accelerator/Overview.html">7.1. Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_accelerator/Components_of_Hardware_Accelerators.html">7.2. Components of Hardware Accelerators</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_accelerator/Programming_Methods.html">7.3. Programming Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_accelerator/Performance_Optimization_Methods.html">7.4. Performance Optimization Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_accelerator/Chapter_Summary.html">7.5. Chapter Summary</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_distributed/index.html">8. Distributed Training</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed/Overview.html">8.1. Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed/Parallelism_Methods.html">8.2. Parallelism Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed/Pipeline_Parallelism_with_Micro-Batching.html">8.3. Pipeline Parallelism with Micro-Batching</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed/Architecture_of_Machine_Learning_Clusters.html">8.4. Architecture of Machine Learning Clusters</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed/Collective_Communication.html">8.5. Collective Communication</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed/Parameter_Server.html">8.6. Parameter Server</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed/Federated_Learning.html">8.7. Federated Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed/Training_Large_Language_Models.html">8.8. Training Large Language Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed/Chapter_Summary.html">8.9. Chapter Summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed/Further_Reading.html">8.10. Further Reading</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_model_deployment/index.html">9. Model Deployment</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/Overview.html">9.1. Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/Conversion_to_Inference_Model_and_Model_Optimization.html">9.2. Conversion to Inference Model and Model Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/Model_Compression.html">9.3. Model Compression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/Advanced_Efficient_Techniques.html">9.4. Advanced Efficient Techniques</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/Model_Inference.html">9.5. Model Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/Security_Protection_of_Models.html">9.6. Security Protection of Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/Chapter_Summary.html">9.7. Chapter Summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/Further_Reading.html">9.8. Further Reading</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preface_extension/index.html">10. Part II Application Scenarios</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">11. Recommender System</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="Overview.html">11.1. Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="System_Components.html">11.2. System Components</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">11.3. Recommendation Pipeline</a></li>
<li class="toctree-l2"><a class="reference internal" href="Model_Update.html">11.4. Model Update</a></li>
<li class="toctree-l2"><a class="reference internal" href="Supporting_Real-time_Machine_Learning.html">11.5. Supporting Real-time Machine Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="Chapter_Summary.html">11.6. Chapter Summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="Further_Reading.html">11.7. Further Reading</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_reinforcement_learning/index.html">12. Reinforcement Learning System</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/Overview.html">12.1. Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/Introduction_to_Reinforcement_Learning.html">12.2. Introduction to Reinforcement Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/Single-Node_Reinforcement_Learning_System.html">12.3. Single-Node Reinforcement Learning System</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/Distributed_Reinforcement_Learning_System.html">12.4. Distributed Reinforcement Learning System</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/Multi-agent_Reinforcement_Learning.html">12.5. Multi-agent Reinforcement Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/Multi-agent_Reinforcement_Learning_System.html">12.6. Multi-agent Reinforcement Learning System</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/Chapter_Summary.html">12.7. Chapter Summary</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_robot/index.html">13. Robotic System</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_robot/Overview_of_Robotic_Systems.html">13.1. Overview of Robotic Systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_robot/Robot_Operating_System.html">13.2. Robot Operating System</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_robot/Case_Study.html">13.3. Case Study: Using ROS</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_robot/Modern_Robot_Learning.html">13.4. Modern Robot Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_robot/Chapter_Summary.html">13.5. Chapter Summary</a></li>
</ul>
</li>
</ul>

            </nav>
        
        </div>
    
</header>
        <main class="mdl-layout__content" tabIndex="0">

	<script type="text/javascript" src="../_static/sphinx_materialdesign_theme.js "></script>
    <header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <img class="logo" src="../_static/logo-with-text.png" alt="Machine Learning Systems: Design and Implementation"/>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../chapter_preface/index.html">1. Preface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_introduction/index.html">2. Introduction</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/Machine_Learning_Applications.html">2.1. Machine Learning Applications</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/Design_Objectives_of_Machine_Learning_Frameworks.html">2.2. Design Objectives of Machine Learning Frameworks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/Machine_Learning_Framework_Architecture.html">2.3. Machine Learning Framework Architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/Application_Scenarios_of_Machine_Learning_Systems.html">2.4. Application Scenarios of Machine Learning Systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/Book_Organization_and_Intended_Audience.html">2.5. Book Organization and Intended Audience</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preface_basic/index.html">3. Part I Framework Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_programming_model/index.html">4. Programming Model</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_model/Overview.html">4.1. Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_model/Machine_Learning_Workflow.html">4.2. Machine Learning Workflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_model/Neural_Network_Programming.html">4.3. Neural Network Programming</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_model/Functional_Programming.html">4.4. Functional Programming</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_model/Bridging_Python_and_C_C%2B%2B_Functions.html">4.5. Bridging Python and C/C++ Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_model/Chapter_Summary.html">4.6. Chapter Summary</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_compiler_frontend/index.html">5. AI Compiler Frontend</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_frontend/Overview_of_AI_Compilers.html">5.1. Overview of AI Compilers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_frontend/Overview_of_AI_Compiler_Frontends.html">5.2. Overview of AI Compiler Frontends</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_frontend/Intermediate_Representation.html">5.3. Intermediate Representation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_frontend/Automatic_Differentiation.html">5.4. Automatic Differentiation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_frontend/Type_Systems_and_Static_Analysis.html">5.5. Type Systems and Static Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_frontend/Frontend_Compilation_Optimization.html">5.6. Frontend Compilation Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_frontend/Chapter_Summary.html">5.7. Chapter Summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_frontend/Further_Reading.html">5.8. Further Reading</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_compiler_backend/index.html">6. AI Compiler Backend</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_backend/Overview.html">6.1. Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_backend/Graph_Optimization.html">6.2. Graph Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_backend/Operator_Selection.html">6.3. Operator Selection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_backend/Memory_Allocation.html">6.4. Memory Allocation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_backend/Operator_Compiler.html">6.5. Operator Compiler</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_backend/Chapter_Summary.html">6.6. Chapter Summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_backend/Further_Reading.html">6.7. Further Reading</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_accelerator/index.html">7. Hardware Accelerator</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_accelerator/Overview.html">7.1. Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_accelerator/Components_of_Hardware_Accelerators.html">7.2. Components of Hardware Accelerators</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_accelerator/Programming_Methods.html">7.3. Programming Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_accelerator/Performance_Optimization_Methods.html">7.4. Performance Optimization Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_accelerator/Chapter_Summary.html">7.5. Chapter Summary</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_distributed/index.html">8. Distributed Training</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed/Overview.html">8.1. Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed/Parallelism_Methods.html">8.2. Parallelism Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed/Pipeline_Parallelism_with_Micro-Batching.html">8.3. Pipeline Parallelism with Micro-Batching</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed/Architecture_of_Machine_Learning_Clusters.html">8.4. Architecture of Machine Learning Clusters</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed/Collective_Communication.html">8.5. Collective Communication</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed/Parameter_Server.html">8.6. Parameter Server</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed/Federated_Learning.html">8.7. Federated Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed/Training_Large_Language_Models.html">8.8. Training Large Language Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed/Chapter_Summary.html">8.9. Chapter Summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed/Further_Reading.html">8.10. Further Reading</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_model_deployment/index.html">9. Model Deployment</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/Overview.html">9.1. Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/Conversion_to_Inference_Model_and_Model_Optimization.html">9.2. Conversion to Inference Model and Model Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/Model_Compression.html">9.3. Model Compression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/Advanced_Efficient_Techniques.html">9.4. Advanced Efficient Techniques</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/Model_Inference.html">9.5. Model Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/Security_Protection_of_Models.html">9.6. Security Protection of Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/Chapter_Summary.html">9.7. Chapter Summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/Further_Reading.html">9.8. Further Reading</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preface_extension/index.html">10. Part II Application Scenarios</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">11. Recommender System</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="Overview.html">11.1. Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="System_Components.html">11.2. System Components</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">11.3. Recommendation Pipeline</a></li>
<li class="toctree-l2"><a class="reference internal" href="Model_Update.html">11.4. Model Update</a></li>
<li class="toctree-l2"><a class="reference internal" href="Supporting_Real-time_Machine_Learning.html">11.5. Supporting Real-time Machine Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="Chapter_Summary.html">11.6. Chapter Summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="Further_Reading.html">11.7. Further Reading</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_reinforcement_learning/index.html">12. Reinforcement Learning System</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/Overview.html">12.1. Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/Introduction_to_Reinforcement_Learning.html">12.2. Introduction to Reinforcement Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/Single-Node_Reinforcement_Learning_System.html">12.3. Single-Node Reinforcement Learning System</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/Distributed_Reinforcement_Learning_System.html">12.4. Distributed Reinforcement Learning System</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/Multi-agent_Reinforcement_Learning.html">12.5. Multi-agent Reinforcement Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/Multi-agent_Reinforcement_Learning_System.html">12.6. Multi-agent Reinforcement Learning System</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/Chapter_Summary.html">12.7. Chapter Summary</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_robot/index.html">13. Robotic System</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_robot/Overview_of_Robotic_Systems.html">13.1. Overview of Robotic Systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_robot/Robot_Operating_System.html">13.2. Robot Operating System</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_robot/Case_Study.html">13.3. Case Study: Using ROS</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_robot/Modern_Robot_Learning.html">13.4. Modern Robot Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_robot/Chapter_Summary.html">13.5. Chapter Summary</a></li>
</ul>
</li>
</ul>

            </nav>
        
        </div>
    
</header>

    <div class="document">
        <div class="page-content" role="main">
        
  <div class="section" id="recommendation-pipeline">
<h1><span class="section-number">11.3. </span>Recommendation Pipeline<a class="headerlink" href="#recommendation-pipeline" title="Permalink to this heading">¶</a></h1>
<p>A recommendation pipeline, designed to suggest items of potential
interest to users based on their requests, is an integral part of any
recommender system. Specifically, a user seeking recommendations submits
a request that includes their user ID and the current context features,
such as recently browsed items and browsing duration, to the inference
service. The recommendation pipeline uses these user features and those
of potential items as input for computation. It then derives a score for
each candidate item, selects the highest-scoring items (ranging from
dozens to hundreds) to form the recommendation result, and delivers this
result back to the user.</p>
<p>Given that a recommender system generally contains billions of potential
items, using just a single model to compute the score of each item
necessitates a trade-off between model accuracy and speed. In other
words, opting for a simpler model may boost speed but potentially result
in recommendations that fail to pique the user’s interest due to
diminished accuracy. On the other hand, using a more complex model may
provide more accurate results but deter users due to longer waiting
times.</p>
<div class="figure align-default" id="id6">
<span id="recommender-pipeline"></span><img alt="../_images/recommender_pipeline.png" src="../_images/recommender_pipeline.png" />
<p class="caption"><span class="caption-number">Fig. 11.3.1 </span><span class="caption-text">Example of a multi-stage recommendationpipeline</span><a class="headerlink" href="#id6" title="Permalink to this image">¶</a></p>
</div>
<p>To mitigate this, contemporary recommender systems typically deploy
multiple recommendation models as part of a pipeline, as illustrated in
Figure <a class="reference internal" href="#recommender-pipeline"><span class="std std-numref">Fig. 11.3.1</span></a>. The pipeline begins with the
retrieval stage, employing fast, simple models to filter the entire pool
of candidate items, identifying thousands to tens of thousands of items
that the user may find appealing. Following this, in the ranking stage,
slower, more complex models score and order the retrieved items. The
top-scoring items (the exact number may vary depending on the specific
service scenario), numbering in the dozens or hundreds, are returned as
the final recommendation. If the ranking models are too intricate and
cannot process all retrieved items within the given time frame, the
ranking stage may be further divided into three sub-stages: pre-ranking,
ranking, and re-ranking.</p>
<div class="section" id="retrieval-stage">
<h2><span class="section-number">11.3.1. </span>Retrieval Stage<a class="headerlink" href="#retrieval-stage" title="Permalink to this heading">¶</a></h2>
<p>The retrieval stage is the initial phase of the recommendation process.
The model takes user features as input and performs a rough filter of
all candidate items to identify those the user might be interested in.
These selected items form the output. The main goal of the retrieval
stage is to reduce the pool of candidate items, thereby lightening the
computational load on the ranking model in the subsequent stage.</p>
<div class="section" id="two-tower-model">
<h3><span class="section-number">11.3.1.1. </span>Two-Tower Model<a class="headerlink" href="#two-tower-model" title="Permalink to this heading">¶</a></h3>
<p>To illustrate the retrieval process, let’s consider the two-tower model
as an example, as shown in Figure <a class="reference internal" href="#id2"><span class="std std-numref">Fig. 11.3.2</span></a>. The
two-tower model contains two multilayer perceptrons (MLPs) which encode
user features and item features, referred to as the user tower <a class="footnote-reference brackets" href="#id4" id="id1">1</a> and
item tower, respectively.</p>
<p>Continuous features can be input directly into the MLPs, while discrete
features must first be mapped into a dense vector using embedding tables
before being fed into the MLPs. The user tower and item tower process
these features to generate user vectors and item vectors, respectively,
each representing a unique user or item. The two-tower model employs a
scoring function to evaluate the similarity between user vectors and
item vectors.</p>
<div class="figure align-default" id="id7">
<span id="id2"></span><img alt="../_images/two_tower_model.png" src="../_images/two_tower_model.png" />
<p class="caption"><span class="caption-number">Fig. 11.3.2 </span><span class="caption-text">Structure of the two-towermodel</span><a class="headerlink" href="#id7" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="training">
<h3><span class="section-number">11.3.1.2. </span>Training<a class="headerlink" href="#training" title="Permalink to this heading">¶</a></h3>
<p>During training, the model input consists of the user’s feedback data on
historical recommendation results, represented by the tuple &lt;user, item,
label&gt;. The label denotes whether the user has clicked the item, with 1
and 0 typically representing a click and non-click, respectively. The
two-tower model uses positive samples (i.e., samples where the label is
1) for training. To obtain negative samples, an intra-batch sampler that
corrects sampling bias performs sampling within the batch. The details
of the algorithm, while not the focus here, can be found in the original
paper.</p>
<p>The model’s output consists of the click probabilities for different
items. During training, a suitable loss function is chosen to ensure
that the predicted results for positive samples are as close to 1 as
possible, and as close to 0 as possible for negative samples.</p>
</div>
<div class="section" id="inference">
<h3><span class="section-number">11.3.1.3. </span>Inference<a class="headerlink" href="#inference" title="Permalink to this heading">¶</a></h3>
<p>Before inference, item vectors for all items are computed and saved
using the trained model. Given that item features are relatively stable,
this step can reduce computational overhead during inference and speed
up the process. User features, which are related to user behavior, are
processed when user requests arrive. The two-tower model uses the user
tower to compute current user features and generate the user vector. The
same scoring function used during training is then used to measure
similarity. This enables similarity search based on the user vector
across all candidate item vectors. The most similar items are output as
the retrieval result.</p>
</div>
<div class="section" id="evaluation-metrics">
<h3><span class="section-number">11.3.1.4. </span>Evaluation Metrics<a class="headerlink" href="#evaluation-metrics" title="Permalink to this heading">¶</a></h3>
<p>A common evaluation metric of the retrieval model is the recall metric
when <span class="math notranslate nohighlight">\(k\)</span> items are recalled (Recall&#64;k). This metric essentially
quantifies the ability of a model to successfully retrieve the top
<span class="math notranslate nohighlight">\(k\)</span> items of interest.</p>
<p>The mathematical definition of Recall&#64;k is expressed as follows:</p>
<div class="math notranslate nohighlight" id="equation-chapter-recommender-system-recommendation-pipeline-0">
<span class="eqno">(11.3.1)<a class="headerlink" href="#equation-chapter-recommender-system-recommendation-pipeline-0" title="Permalink to this equation">¶</a></span>\[\text{Recall&#64;k} = \frac{\text{TP}}{\min(\text{TP} + \text{FN}, k)}\]</div>
<p>In this equation, the term “True Positive” (TP) refers to the count of
items correctly identified by the model as relevant (i.e., with a true
label of 1) among the <span class="math notranslate nohighlight">\(k\)</span> items retrieved. On the other hand,
“False Negative” (FN) denotes the count of relevant items (again, with a
true label of 1) that the model failed to include among the <span class="math notranslate nohighlight">\(k\)</span>
retrieved items.</p>
<p>Thus, the Recall&#64;k metric serves as a measure of the model’s ability to
correctly identify and retrieve positive samples. Importantly, it is
crucial to understand that if the total number of positive samples
surpasses <span class="math notranslate nohighlight">\(k\)</span>, the maximum possible count of correctly retrieved
items is <span class="math notranslate nohighlight">\(k\)</span>. This is due to the fact that the model is limited to
retrieving only <span class="math notranslate nohighlight">\(k\)</span> items. Consequently, the denominator in the
Recall&#64;k equation is defined as the lesser of two quantities: the sum of
true positives and false negatives, or <span class="math notranslate nohighlight">\(k\)</span>.</p>
</div>
</div>
<div class="section" id="ranking-stage">
<h2><span class="section-number">11.3.2. </span>Ranking Stage<a class="headerlink" href="#ranking-stage" title="Permalink to this heading">¶</a></h2>
<p>During the ranking phase, the model appraises the items gathered in the
retrieval stage, evaluating each individually in terms of user features
and item features. Each item’s score is indicative of the probability
that the user might be interested in that item. As a result, the
highest-scoring items based on these rankings are then suggested to the
user.</p>
<p>If the number of candidate items evaluated by the recommendation model
continually increases, or if the recommendation logic and rules become
more complex, the entire ranking stage can be efficiently divided into
three sub-stages: pre-ranking, ranking, and re-ranking.</p>
<div class="section" id="pre-ranking">
<h3><span class="section-number">11.3.2.1. </span>Pre-ranking<a class="headerlink" href="#pre-ranking" title="Permalink to this heading">¶</a></h3>
<p>Acting as an intermediary between the retrieval and ranking stages, the
pre-ranking stage serves as an additional layer of filtering. This
becomes particularly useful when there’s a large influx of candidate
items from the retrieval stage, or when multi-channel retrieval methods
are used to boost retrieval result diversity. If every retrieved item
was directly fed into the ranking model, the subsequent process could
become overly lengthy due to the sheer volume of items. Thus,
introducing a pre-ranking stage to the recommendation pipeline reduces
the number of items proceeding to the ranking stage, enhancing overall
system efficiency.</p>
</div>
<div class="section" id="ranking">
<h3><span class="section-number">11.3.2.2. </span>Ranking<a class="headerlink" href="#ranking" title="Permalink to this heading">¶</a></h3>
<p>Ranking, the second stage, is pivotal in the pipeline. In this phase,
it’s essential that the model precisely represents the user’s
preferences across varying items. When referring to the “ranking model”
in subsequent sections, we are specifically addressing the model used
during this ranking sub-stage.</p>
</div>
<div class="section" id="re-ranking">
<h3><span class="section-number">11.3.2.3. </span>Re-ranking<a class="headerlink" href="#re-ranking" title="Permalink to this heading">¶</a></h3>
<p>In the final re-ranking stage, the preliminary outcomes derived from the
ranking stage are further refined according to specific business logic
and rules. The goal of this stage is to improve the holistic quality of
the recommendation service, shifting the focus from the click-through
rate (CTR) of a single item to the broader user experience. For
instance, the applied business logic might include efforts to increase
the visibility of new items, filter out previously purchased items or
watched videos, and create rules to diversify the order and variety of
recommended items, thereby decreasing the frequency of similar item
recommendations.</p>
</div>
</div>
<div class="section" id="ranking-with-deep-learning">
<h2><span class="section-number">11.3.3. </span>Ranking with Deep Learning<a class="headerlink" href="#ranking-with-deep-learning" title="Permalink to this heading">¶</a></h2>
<p>The ranking stage in a recommender system has largely benefited from the
use of deep learning models. These models are often referred to as the
Deep Learning Recommendation Model (DLRM). As depicted in Figure
<a class="reference internal" href="#dlrm-model"><span class="std std-numref">Fig. 11.3.3</span></a>, a DLRM consists of embedding tables, multi-layer
perceptrons (MLPs) that include two layers, and an interaction
layer. <a class="footnote-reference brackets" href="#id5" id="id3">2</a></p>
<div class="figure align-default" id="id8">
<span id="dlrm-model"></span><img alt="../_images/dlrm_model.png" src="../_images/dlrm_model.png" />
<p class="caption"><span class="caption-number">Fig. 11.3.3 </span><span class="caption-text">Structure of DLRM</span><a class="headerlink" href="#id8" title="Permalink to this image">¶</a></p>
</div>
<p>Similar to the two-tower model, the DLRM initially uses embedding tables
to transform discrete features into corresponding embedding items, which
are represented as dense vectors. The model then combines all continuous
features into a single vector, which is introduced into the bottom MLP,
generating an output vector with the same dimension as the embedding
items. Both this output vector and all the embedding items are then
forwarded to the interaction layer for further processing.</p>
<p>As illustrated in Figure <a class="reference internal" href="#interaction"><span class="std std-numref">Fig. 11.3.4</span></a>, the interaction layer
performs dot product operations on all features (encompassing all
embedding items and the processed continuous features) to obtain
second-order interactions. As the features interacted within the
interaction layer are symmetric, the diagonal represents each feature’s
self-interaction result. In the non-diagonal section, every distinct
pair of features interacts twice (e.g., for features <span class="math notranslate nohighlight">\(p\)</span> and
<span class="math notranslate nohighlight">\(q\)</span>, two results are acquired: <span class="math notranslate nohighlight">\(&lt;p,q&gt;\)</span> and <span class="math notranslate nohighlight">\(&lt;q,p&gt;\)</span>).
Therefore, only the lower triangular part of the result matrix is
retained and flattened. This flattened interaction result is merged with
the output from the bottom MLP, and the combined result is used as the
input for the top MLP. After further processing by the top MLP, the
final output score reflects the probability of a user clicking on the
item.</p>
<div class="figure align-default" id="id9">
<span id="interaction"></span><img alt="../_images/interaction.png" src="../_images/interaction.png" />
<p class="caption"><span class="caption-number">Fig. 11.3.4 </span><span class="caption-text">Interaction principlediagram</span><a class="headerlink" href="#id9" title="Permalink to this image">¶</a></p>
</div>
<div class="section" id="training-process">
<h3><span class="section-number">11.3.3.1. </span>Training Process<a class="headerlink" href="#training-process" title="Permalink to this heading">¶</a></h3>
<p>The DLRM bases its training on &lt;user, item, label&gt; tuples. It takes in
user and item features as inputs and interacts with these features to
predict the likelihood of a user clicking an item. For positive samples,
the model aims to approximate this probability as closely to 1 as
possible, while for negative samples, the goal is to get this
probability as near to 0 as possible.</p>
<p>The ranking process can be considered a binary classification problem;
the (user, item) pair can be classified either as click (label: 1) or no
click (label: 0). Therefore, the method used to evaluate a ranking model
is analogous to that employed for assessing a binary classification
model. However, it’s crucial to consider that recommender system
datasets tend to be extremely imbalanced, meaning the proportion of
positive samples is drastically different from that of negative samples.
To minimize the influence of this data imbalance on metrics, we use the
Area Under the Curve (AUC) and F1 score to evaluate ranking models.</p>
<p>The AUC is the area under the Receiver Operating Characteristic (ROC)
curve, a graph used to define classification thresholds, plotted with
the True Positive Rate (TPR) against the False Positive Rate (FPR) —
with the TPR on the y-axis and the FPR on the x-axis. An appropriate
classification threshold can be determined by calculating the AUC and
the ROC curves. If the predicted probability exceeds the classification
threshold, the prediction result is 1 (click); otherwise, it is 0 (no
click). From the prediction result, recall and precision can be
computed, which in turn allows for the calculation of the F1 score using
the formula <code class="xref eq docutils literal notranslate"><span class="pre">f1</span></code>.</p>
<div class="math notranslate nohighlight" id="equation-chapter-recommender-system-recommendation-pipeline-1">
<span class="eqno">(11.3.2)<a class="headerlink" href="#equation-chapter-recommender-system-recommendation-pipeline-1" title="Permalink to this equation">¶</a></span>\[F1 = 2 \times \frac{recall \times precision}{recall + precision}\]</div>
<p>:eqlabel:<code class="docutils literal notranslate"><span class="pre">equ:f1</span></code></p>
</div>
<div class="section" id="inference-process">
<h3><span class="section-number">11.3.3.2. </span>Inference Process<a class="headerlink" href="#inference-process" title="Permalink to this heading">¶</a></h3>
<p>During the inference stage, the features of the retrieved items, along
with their corresponding user features, are merged and inputted into the
DLRM. The model then predicts scores, and the items with the highest
probabilities are selected for output.</p>
<dl class="footnote brackets">
<dt class="label" id="id4"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p>In the original paper, the user tower also uses the features of
videos watched by users as seed features.</p>
</dd>
<dt class="label" id="id5"><span class="brackets"><a class="fn-backref" href="#id3">2</a></span></dt>
<dd><p>DLRM is designed for structural customization. This section will
illustrate an example using the standard code implementation of DLRM.</p>
</dd>
</dl>
</div>
</div>
</div>


        </div>
        <div class="side-doc-outline">
            <div class="side-doc-outline--content"> 
<div class="localtoc">
    <p class="caption">
      <span class="caption-text">Table Of Contents</span>
    </p>
    <ul>
<li><a class="reference internal" href="#">11.3. Recommendation Pipeline</a><ul>
<li><a class="reference internal" href="#retrieval-stage">11.3.1. Retrieval Stage</a><ul>
<li><a class="reference internal" href="#two-tower-model">11.3.1.1. Two-Tower Model</a></li>
<li><a class="reference internal" href="#training">11.3.1.2. Training</a></li>
<li><a class="reference internal" href="#inference">11.3.1.3. Inference</a></li>
<li><a class="reference internal" href="#evaluation-metrics">11.3.1.4. Evaluation Metrics</a></li>
</ul>
</li>
<li><a class="reference internal" href="#ranking-stage">11.3.2. Ranking Stage</a><ul>
<li><a class="reference internal" href="#pre-ranking">11.3.2.1. Pre-ranking</a></li>
<li><a class="reference internal" href="#ranking">11.3.2.2. Ranking</a></li>
<li><a class="reference internal" href="#re-ranking">11.3.2.3. Re-ranking</a></li>
</ul>
</li>
<li><a class="reference internal" href="#ranking-with-deep-learning">11.3.3. Ranking with Deep Learning</a><ul>
<li><a class="reference internal" href="#training-process">11.3.3.1. Training Process</a></li>
<li><a class="reference internal" href="#inference-process">11.3.3.2. Inference Process</a></li>
</ul>
</li>
</ul>
</li>
</ul>

</div>
            </div>
        </div>

      <div class="clearer"></div>
    </div><div class="pagenation">
     <a id="button-prev" href="System_Components.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="P">
         <i class="pagenation-arrow-L fas fa-arrow-left fa-lg"></i>
         <div class="pagenation-text">
            <span class="pagenation-direction">Previous</span>
            <div>11.2. System Components</div>
         </div>
     </a>
     <a id="button-next" href="Model_Update.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="N">
         <i class="pagenation-arrow-R fas fa-arrow-right fa-lg"></i>
        <div class="pagenation-text">
            <span class="pagenation-direction">Next</span>
            <div>11.4. Model Update</div>
        </div>
     </a>
  </div>
        
        </main>
    </div>
  </body>
</html>