<!DOCTYPE html>
<html lang="en">
 <head>
  <meta charset="utf-8"/>
  <meta content="width=device-width, initial-scale=1.0" name="viewport"/>
  <meta charset="utf-8"/>
  <meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
  <meta content="ie=edge" http-equiv="x-ua-compatible"/>
  <title>
   9.2. Conversion to Inference Model and Model Optimization — Machine Learning Systems: Design and Implementation 1.0.0 documentation
  </title>
  <link href="../_static/material-design-lite-1.3.0/material.blue-deep_orange.min.css" rel="stylesheet" type="text/css"/>
  <link href="../_static/sphinx_materialdesign_theme.css" rel="stylesheet" type="text/css"/>
  <link href="../_static/fontawesome/all.css" rel="stylesheet" type="text/css"/>
  <link href="../_static/fonts.css" rel="stylesheet" type="text/css"/>
  <link href="../_static/pygments.css" rel="stylesheet" type="text/css"/>
  <link href="../_static/basic.css" rel="stylesheet" type="text/css"/>
  <link href="../_static/d2l.css" rel="stylesheet" type="text/css"/>
  <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js">
  </script>
  <script src="../_static/jquery.js">
  </script>
  <script src="../_static/underscore.js">
  </script>
  <script src="../_static/_sphinx_javascript_frameworks_compat.js">
  </script>
  <script src="../_static/doctools.js">
  </script>
  <script src="../_static/sphinx_highlight.js">
  </script>
  <script src="../_static/d2l.js">
  </script>
  <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>
  <link href="../_static/favicon.png" rel="shortcut icon"/>
  <link href="../genindex.html" rel="index" title="Index"/>
  <link href="../search.html" rel="search" title="Search"/>
  <link href="Model_Compression.html" rel="next" title="9.3. Model Compression"/>
  <link href="Overview.html" rel="prev" title="9.1. Overview"/>
 </head>
 <body>
  <div class="mdl-layout mdl-js-layout mdl-layout--fixed-header mdl-layout--fixed-drawer">
   <header class="mdl-layout__header mdl-layout__header--waterfall">
    <div class="mdl-layout__header-row">
     <nav class="mdl-navigation breadcrumb">
      <a class="mdl-navigation__link" href="index.html">
       <span class="section-number">
        9.
       </span>
       Model Deployment
      </a>
      <i class="material-icons">
       navigate_next
      </i>
      <a class="mdl-navigation__link is-active">
       <span class="section-number">
        9.2.
       </span>
       Conversion to Inference Model and Model Optimization
      </a>
     </nav>
     <div class="mdl-layout-spacer">
     </div>
     <nav class="mdl-navigation">
      <form action="../search.html" class="form-inline pull-sm-right" method="get">
       <div class="mdl-textfield mdl-js-textfield mdl-textfield--expandable mdl-textfield--floating-label mdl-textfield--align-right">
        <label class="mdl-button mdl-js-button mdl-button--icon" for="waterfall-exp" id="quick-search-icon">
         <i class="material-icons">
          search
         </i>
        </label>
        <div class="mdl-textfield__expandable-holder">
         <input class="mdl-textfield__input" id="waterfall-exp" name="q" placeholder="Search" type="text"/>
         <input name="check_keywords" type="hidden" value="yes"/>
         <input name="area" type="hidden" value="default"/>
        </div>
       </div>
       <div class="mdl-tooltip" data-mdl-for="quick-search-icon">
        Quick search
       </div>
      </form>
      <a class="mdl-button mdl-js-button mdl-button--icon" href="../_sources/chapter_model_deployment/Conversion_to_Inference_Model_and_Model_Optimization.rst.txt" id="button-show-source" rel="nofollow">
       <i class="material-icons">
        code
       </i>
      </a>
      <div class="mdl-tooltip" data-mdl-for="button-show-source">
       Show Source
      </div>
     </nav>
    </div>
    <div class="mdl-layout__header-row header-links">
     <div class="mdl-layout-spacer">
     </div>
     <nav class="mdl-navigation">
      <a class="mdl-navigation__link" href="https://github.com/openmlsys/openmlsys-en">
       <i class="fab fa-github">
       </i>
       GitHub
      </a>
      <a class="mdl-navigation__link" href="https://openmlsys.github.io/">
       <i class="fas fa-external-link-alt">
       </i>
       中文版
      </a>
     </nav>
    </div>
   </header>
   <header class="mdl-layout__drawer">
    <!-- Title -->
    <span class="mdl-layout-title">
     <a class="title" href="../index.html">
      <img alt="Machine Learning Systems: Design and Implementation" class="logo" src="../_static/logo-with-text.png"/>
     </a>
    </span>
    <div class="globaltoc">
     <span class="mdl-layout-title toc">
      Table Of Contents
     </span>
     <nav class="mdl-navigation">
      <ul class="current">
       <li class="toctree-l1">
        <a class="reference internal" href="../chapter_preface/index.html">
         1. Preface
        </a>
       </li>
       <li class="toctree-l1">
        <a class="reference internal" href="../chapter_introduction/index.html">
         2. Introduction
        </a>
        <ul>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_introduction/Machine_Learning_Applications.html">
           2.1. Machine Learning Applications
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_introduction/Design_Objectives_of_Machine_Learning_Frameworks.html">
           2.2. Design Objectives of Machine Learning Frameworks
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_introduction/Machine_Learning_Framework_Architecture.html">
           2.3. Machine Learning Framework Architecture
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_introduction/Application_Scenarios_of_Machine_Learning_Systems.html">
           2.4. Application Scenarios of Machine Learning Systems
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_introduction/Book_Organization_and_Intended_Audience.html">
           2.5. Book Organization and Intended Audience
          </a>
         </li>
        </ul>
       </li>
       <li class="toctree-l1">
        <a class="reference internal" href="../chapter_preface_basic/index.html">
         3. Part I Framework Design
        </a>
       </li>
       <li class="toctree-l1">
        <a class="reference internal" href="../chapter_programming_model/index.html">
         4. Programming Model
        </a>
        <ul>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_programming_model/Overview.html">
           4.1. Overview
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_programming_model/Machine_Learning_Workflow.html">
           4.2. Machine Learning Workflow
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_programming_model/Neural_Network_Programming.html">
           4.3. Neural Network Programming
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_programming_model/Functional_Programming.html">
           4.4. Functional Programming
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_programming_model/Bridging_Python_and_C_C%2B%2B_Functions.html">
           4.5. Bridging Python and C/C++ Functions
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_programming_model/Chapter_Summary.html">
           4.6. Chapter Summary
          </a>
         </li>
        </ul>
       </li>
       <li class="toctree-l1">
        <a class="reference internal" href="../chapter_compiler_frontend/index.html">
         5. AI Compiler Frontend
        </a>
        <ul>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_compiler_frontend/Overview_of_AI_Compilers.html">
           5.1. Overview of AI Compilers
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_compiler_frontend/Overview_of_AI_Compiler_Frontends.html">
           5.2. Overview of AI Compiler Frontends
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_compiler_frontend/Intermediate_Representation.html">
           5.3. Intermediate Representation
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_compiler_frontend/Automatic_Differentiation.html">
           5.4. Automatic Differentiation
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_compiler_frontend/Type_Systems_and_Static_Analysis.html">
           5.5. Type Systems and Static Analysis
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_compiler_frontend/Frontend_Compilation_Optimization.html">
           5.6. Frontend Compilation Optimization
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_compiler_frontend/Chapter_Summary.html">
           5.7. Chapter Summary
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_compiler_frontend/Further_Reading.html">
           5.8. Further Reading
          </a>
         </li>
        </ul>
       </li>
       <li class="toctree-l1">
        <a class="reference internal" href="../chapter_compiler_backend/index.html">
         6. AI Compiler Backend
        </a>
        <ul>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_compiler_backend/Overview.html">
           6.1. Overview
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_compiler_backend/Graph_Optimization.html">
           6.2. Graph Optimization
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_compiler_backend/Operator_Selection.html">
           6.3. Operator Selection
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_compiler_backend/Memory_Allocation.html">
           6.4. Memory Allocation
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_compiler_backend/Operator_Compiler.html">
           6.5. Operator Compiler
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_compiler_backend/Chapter_Summary.html">
           6.6. Chapter Summary
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_compiler_backend/Further_Reading.html">
           6.7. Further Reading
          </a>
         </li>
        </ul>
       </li>
       <li class="toctree-l1">
        <a class="reference internal" href="../chapter_accelerator/index.html">
         7. Hardware Accelerator
        </a>
        <ul>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_accelerator/Overview.html">
           7.1. Overview
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_accelerator/Components_of_Hardware_Accelerators.html">
           7.2. Components of Hardware Accelerators
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_accelerator/Programming_Methods.html">
           7.3. Programming Methods
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_accelerator/Performance_Optimization_Methods.html">
           7.4. Performance Optimization Methods
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_accelerator/Chapter_Summary.html">
           7.5. Chapter Summary
          </a>
         </li>
        </ul>
       </li>
       <li class="toctree-l1">
        <a class="reference internal" href="../chapter_distributed/index.html">
         8. Distributed Training
        </a>
        <ul>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_distributed/Overview.html">
           8.1. Overview
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_distributed/Parallelism_Methods.html">
           8.2. Parallelism Methods
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_distributed/Pipeline_Parallelism_with_Micro-Batching.html">
           8.3. Pipeline Parallelism with Micro-Batching
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_distributed/Architecture_of_Machine_Learning_Clusters.html">
           8.4. Architecture of Machine Learning Clusters
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_distributed/Collective_Communication.html">
           8.5. Collective Communication
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_distributed/Parameter_Server.html">
           8.6. Parameter Server
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_distributed/Federated_Learning.html">
           8.7. Federated Learning
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_distributed/Training_Large_Language_Models.html">
           8.8. Training Large Language Models
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_distributed/Chapter_Summary.html">
           8.9. Chapter Summary
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_distributed/Further_Reading.html">
           8.10. Further Reading
          </a>
         </li>
        </ul>
       </li>
       <li class="toctree-l1 current">
        <a class="reference internal" href="index.html">
         9. Model Deployment
        </a>
        <ul class="current">
         <li class="toctree-l2">
          <a class="reference internal" href="Overview.html">
           9.1. Overview
          </a>
         </li>
         <li class="toctree-l2 current">
          <a class="current reference internal" href="#">
           9.2. Conversion to Inference Model and Model Optimization
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="Model_Compression.html">
           9.3. Model Compression
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="Advanced_Efficient_Techniques.html">
           9.4. Advanced Efficient Techniques
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="Model_Inference.html">
           9.5. Model Inference
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="Security_Protection_of_Models.html">
           9.6. Security Protection of Models
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="Chapter_Summary.html">
           9.7. Chapter Summary
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="Further_Reading.html">
           9.8. Further Reading
          </a>
         </li>
        </ul>
       </li>
       <li class="toctree-l1">
        <a class="reference internal" href="../chapter_preface_extension/index.html">
         10. Part II Application Scenarios
        </a>
       </li>
       <li class="toctree-l1">
        <a class="reference internal" href="../chapter_recommender_system/index.html">
         11. Recommender System
        </a>
        <ul>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_recommender_system/Overview.html">
           11.1. Overview
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_recommender_system/System_Components.html">
           11.2. System Components
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_recommender_system/Recommendation_Pipeline.html">
           11.3. Recommendation Pipeline
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_recommender_system/Model_Update.html">
           11.4. Model Update
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_recommender_system/Supporting_Real-time_Machine_Learning.html">
           11.5. Supporting Real-time Machine Learning
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_recommender_system/Chapter_Summary.html">
           11.6. Chapter Summary
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_recommender_system/Further_Reading.html">
           11.7. Further Reading
          </a>
         </li>
        </ul>
       </li>
       <li class="toctree-l1">
        <a class="reference internal" href="../chapter_reinforcement_learning/index.html">
         12. Reinforcement Learning System
        </a>
        <ul>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_reinforcement_learning/Overview.html">
           12.1. Overview
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_reinforcement_learning/Introduction_to_Reinforcement_Learning.html">
           12.2. Introduction to Reinforcement Learning
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_reinforcement_learning/Single-Node_Reinforcement_Learning_System.html">
           12.3. Single-Node Reinforcement Learning System
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_reinforcement_learning/Distributed_Reinforcement_Learning_System.html">
           12.4. Distributed Reinforcement Learning System
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_reinforcement_learning/Multi-agent_Reinforcement_Learning.html">
           12.5. Multi-agent Reinforcement Learning
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_reinforcement_learning/Multi-agent_Reinforcement_Learning_System.html">
           12.6. Multi-agent Reinforcement Learning System
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_reinforcement_learning/Chapter_Summary.html">
           12.7. Chapter Summary
          </a>
         </li>
        </ul>
       </li>
       <li class="toctree-l1">
        <a class="reference internal" href="../chapter_robot/index.html">
         13. Robotic System
        </a>
        <ul>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_robot/Overview_of_Robotic_Systems.html">
           13.1. Overview of Robotic Systems
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_robot/Robot_Operating_System.html">
           13.2. Robot Operating System
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_robot/Case_Study.html">
           13.3. Case Study: Using ROS
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_robot/Modern_Robot_Learning.html">
           13.4. Modern Robot Learning
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_robot/Chapter_Summary.html">
           13.5. Chapter Summary
          </a>
         </li>
        </ul>
       </li>
      </ul>
     </nav>
    </div>
   </header>
   <main class="mdl-layout__content" tabindex="0">
    <script src="../_static/sphinx_materialdesign_theme.js " type="text/javascript">
    </script>
    <header class="mdl-layout__drawer">
     <!-- Title -->
     <span class="mdl-layout-title">
      <a class="title" href="../index.html">
       <img alt="Machine Learning Systems: Design and Implementation" class="logo" src="../_static/logo-with-text.png"/>
      </a>
     </span>
     <div class="globaltoc">
      <span class="mdl-layout-title toc">
       Table Of Contents
      </span>
      <nav class="mdl-navigation">
       <ul class="current">
        <li class="toctree-l1">
         <a class="reference internal" href="../chapter_preface/index.html">
          1. Preface
         </a>
        </li>
        <li class="toctree-l1">
         <a class="reference internal" href="../chapter_introduction/index.html">
          2. Introduction
         </a>
         <ul>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_introduction/Machine_Learning_Applications.html">
            2.1. Machine Learning Applications
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_introduction/Design_Objectives_of_Machine_Learning_Frameworks.html">
            2.2. Design Objectives of Machine Learning Frameworks
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_introduction/Machine_Learning_Framework_Architecture.html">
            2.3. Machine Learning Framework Architecture
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_introduction/Application_Scenarios_of_Machine_Learning_Systems.html">
            2.4. Application Scenarios of Machine Learning Systems
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_introduction/Book_Organization_and_Intended_Audience.html">
            2.5. Book Organization and Intended Audience
           </a>
          </li>
         </ul>
        </li>
        <li class="toctree-l1">
         <a class="reference internal" href="../chapter_preface_basic/index.html">
          3. Part I Framework Design
         </a>
        </li>
        <li class="toctree-l1">
         <a class="reference internal" href="../chapter_programming_model/index.html">
          4. Programming Model
         </a>
         <ul>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_programming_model/Overview.html">
            4.1. Overview
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_programming_model/Machine_Learning_Workflow.html">
            4.2. Machine Learning Workflow
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_programming_model/Neural_Network_Programming.html">
            4.3. Neural Network Programming
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_programming_model/Functional_Programming.html">
            4.4. Functional Programming
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_programming_model/Bridging_Python_and_C_C%2B%2B_Functions.html">
            4.5. Bridging Python and C/C++ Functions
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_programming_model/Chapter_Summary.html">
            4.6. Chapter Summary
           </a>
          </li>
         </ul>
        </li>
        <li class="toctree-l1">
         <a class="reference internal" href="../chapter_compiler_frontend/index.html">
          5. AI Compiler Frontend
         </a>
         <ul>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_compiler_frontend/Overview_of_AI_Compilers.html">
            5.1. Overview of AI Compilers
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_compiler_frontend/Overview_of_AI_Compiler_Frontends.html">
            5.2. Overview of AI Compiler Frontends
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_compiler_frontend/Intermediate_Representation.html">
            5.3. Intermediate Representation
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_compiler_frontend/Automatic_Differentiation.html">
            5.4. Automatic Differentiation
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_compiler_frontend/Type_Systems_and_Static_Analysis.html">
            5.5. Type Systems and Static Analysis
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_compiler_frontend/Frontend_Compilation_Optimization.html">
            5.6. Frontend Compilation Optimization
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_compiler_frontend/Chapter_Summary.html">
            5.7. Chapter Summary
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_compiler_frontend/Further_Reading.html">
            5.8. Further Reading
           </a>
          </li>
         </ul>
        </li>
        <li class="toctree-l1">
         <a class="reference internal" href="../chapter_compiler_backend/index.html">
          6. AI Compiler Backend
         </a>
         <ul>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_compiler_backend/Overview.html">
            6.1. Overview
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_compiler_backend/Graph_Optimization.html">
            6.2. Graph Optimization
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_compiler_backend/Operator_Selection.html">
            6.3. Operator Selection
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_compiler_backend/Memory_Allocation.html">
            6.4. Memory Allocation
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_compiler_backend/Operator_Compiler.html">
            6.5. Operator Compiler
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_compiler_backend/Chapter_Summary.html">
            6.6. Chapter Summary
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_compiler_backend/Further_Reading.html">
            6.7. Further Reading
           </a>
          </li>
         </ul>
        </li>
        <li class="toctree-l1">
         <a class="reference internal" href="../chapter_accelerator/index.html">
          7. Hardware Accelerator
         </a>
         <ul>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_accelerator/Overview.html">
            7.1. Overview
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_accelerator/Components_of_Hardware_Accelerators.html">
            7.2. Components of Hardware Accelerators
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_accelerator/Programming_Methods.html">
            7.3. Programming Methods
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_accelerator/Performance_Optimization_Methods.html">
            7.4. Performance Optimization Methods
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_accelerator/Chapter_Summary.html">
            7.5. Chapter Summary
           </a>
          </li>
         </ul>
        </li>
        <li class="toctree-l1">
         <a class="reference internal" href="../chapter_distributed/index.html">
          8. Distributed Training
         </a>
         <ul>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_distributed/Overview.html">
            8.1. Overview
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_distributed/Parallelism_Methods.html">
            8.2. Parallelism Methods
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_distributed/Pipeline_Parallelism_with_Micro-Batching.html">
            8.3. Pipeline Parallelism with Micro-Batching
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_distributed/Architecture_of_Machine_Learning_Clusters.html">
            8.4. Architecture of Machine Learning Clusters
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_distributed/Collective_Communication.html">
            8.5. Collective Communication
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_distributed/Parameter_Server.html">
            8.6. Parameter Server
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_distributed/Federated_Learning.html">
            8.7. Federated Learning
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_distributed/Training_Large_Language_Models.html">
            8.8. Training Large Language Models
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_distributed/Chapter_Summary.html">
            8.9. Chapter Summary
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_distributed/Further_Reading.html">
            8.10. Further Reading
           </a>
          </li>
         </ul>
        </li>
        <li class="toctree-l1 current">
         <a class="reference internal" href="index.html">
          9. Model Deployment
         </a>
         <ul class="current">
          <li class="toctree-l2">
           <a class="reference internal" href="Overview.html">
            9.1. Overview
           </a>
          </li>
          <li class="toctree-l2 current">
           <a class="current reference internal" href="#">
            9.2. Conversion to Inference Model and Model Optimization
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="Model_Compression.html">
            9.3. Model Compression
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="Advanced_Efficient_Techniques.html">
            9.4. Advanced Efficient Techniques
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="Model_Inference.html">
            9.5. Model Inference
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="Security_Protection_of_Models.html">
            9.6. Security Protection of Models
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="Chapter_Summary.html">
            9.7. Chapter Summary
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="Further_Reading.html">
            9.8. Further Reading
           </a>
          </li>
         </ul>
        </li>
        <li class="toctree-l1">
         <a class="reference internal" href="../chapter_preface_extension/index.html">
          10. Part II Application Scenarios
         </a>
        </li>
        <li class="toctree-l1">
         <a class="reference internal" href="../chapter_recommender_system/index.html">
          11. Recommender System
         </a>
         <ul>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_recommender_system/Overview.html">
            11.1. Overview
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_recommender_system/System_Components.html">
            11.2. System Components
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_recommender_system/Recommendation_Pipeline.html">
            11.3. Recommendation Pipeline
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_recommender_system/Model_Update.html">
            11.4. Model Update
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_recommender_system/Supporting_Real-time_Machine_Learning.html">
            11.5. Supporting Real-time Machine Learning
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_recommender_system/Chapter_Summary.html">
            11.6. Chapter Summary
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_recommender_system/Further_Reading.html">
            11.7. Further Reading
           </a>
          </li>
         </ul>
        </li>
        <li class="toctree-l1">
         <a class="reference internal" href="../chapter_reinforcement_learning/index.html">
          12. Reinforcement Learning System
         </a>
         <ul>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_reinforcement_learning/Overview.html">
            12.1. Overview
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_reinforcement_learning/Introduction_to_Reinforcement_Learning.html">
            12.2. Introduction to Reinforcement Learning
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_reinforcement_learning/Single-Node_Reinforcement_Learning_System.html">
            12.3. Single-Node Reinforcement Learning System
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_reinforcement_learning/Distributed_Reinforcement_Learning_System.html">
            12.4. Distributed Reinforcement Learning System
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_reinforcement_learning/Multi-agent_Reinforcement_Learning.html">
            12.5. Multi-agent Reinforcement Learning
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_reinforcement_learning/Multi-agent_Reinforcement_Learning_System.html">
            12.6. Multi-agent Reinforcement Learning System
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_reinforcement_learning/Chapter_Summary.html">
            12.7. Chapter Summary
           </a>
          </li>
         </ul>
        </li>
        <li class="toctree-l1">
         <a class="reference internal" href="../chapter_robot/index.html">
          13. Robotic System
         </a>
         <ul>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_robot/Overview_of_Robotic_Systems.html">
            13.1. Overview of Robotic Systems
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_robot/Robot_Operating_System.html">
            13.2. Robot Operating System
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_robot/Case_Study.html">
            13.3. Case Study: Using ROS
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_robot/Modern_Robot_Learning.html">
            13.4. Modern Robot Learning
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_robot/Chapter_Summary.html">
            13.5. Chapter Summary
           </a>
          </li>
         </ul>
        </li>
       </ul>
      </nav>
     </div>
    </header>
    <div class="document">
     <div class="page-content" role="main">
      <div class="section" id="conversion-to-inference-model-and-model-optimization">
       <span id="ch-deploy-model-optimization">
       </span>
       <h1>
        <span class="section-number">
         9.2.
        </span>
        Conversion to Inference Model and Model Optimization
        <a class="headerlink" href="#conversion-to-inference-model-and-model-optimization" title="Permalink to this heading">
         ¶
        </a>
       </h1>
       <div class="section" id="model-conversion">
        <h2>
         <span class="section-number">
          9.2.1.
         </span>
         Model Conversion
         <a class="headerlink" href="#model-conversion" title="Permalink to this heading">
          ¶
         </a>
        </h2>
        <p>
         As mentioned earlier, TensorFlow, PyTorch, MindSpore, MXNet, and CNTK
define their own model data structures. This means that the inference
system needs to convert these structures to a unified one. Open Neural
Network Exchange (ONNX) is designed to implement such conversion. It
supports an extensive range of machine learning operators and converts
models from various frameworks (e.g., TensorFlow and PyTorch) into ONNX
models. Because models are structured data, the conversion process
involves converting the data structure. It starts by analyzing the
similarities and differences between two data structures. If they are
the same, data is transferred; if the structures are similar but with
slight differences, data is mapped; if the structures differ
significantly, extra semantics conversion might be required; and if they
are totally incompatible, the conversion will fail. ONNX features strong
expressive power, meaning that it can convert models from most
frameworks in the industry to compatible ONNX models. If a model is
abstracted as a graph, its data structure can be defined as follows:
        </p>
        <ol class="arabic simple">
         <li>
          <p>
           <strong>
            Topological expression of model:
           </strong>
           The topological connections of a
model are represented as edges in a graph. From the perspective of a
model, these edges define the data flows and control flows in the
model. Based on such definitions, we can extend to the expressions of
the subgraphs, model inputs and outputs, and control flow structures.
For example, the control flow on TensorFlow 1.x is expressed as a
cyclic graph. To prevent the formation of cycles, TensorFlow 1.x uses
operators such as Enter, Exit, Switch, LoopCond, and NextIteration,
whereas ONNX uses operators such as Loop and If. As such, when
converting a TensorFlow1.x control flow model into an ONNX model, the
control flow graph structure in the TensorFlow model must be merged
into a While or If operator on ONNX.
          </p>
         </li>
         <li>
          <p>
           <strong>
            Operator prototype definition:
           </strong>
           Operators can be regarded as data
processing or control flow nodes in a model or as vertices in a
graph. An operator prototype defines the type, inputs, outputs, and
attributes of an operator. For instance, Slice has different
semantics on Caffe and ONNX. To convert a Caffe model into an ONNX
model, we need to map Slice on Caffe to Split on ONNX. FusedBatchnorm
on TensorFlow does not have a mapping operator on Caffe. Rather,
Batchnorm and Scale on Caffe need to be combined to express the same
semantics of FusedBatchnorm on TensorFlow. Generally, the model
conversion process involves converting the topological relationships
and mapping the operator prototypes between models.
          </p>
         </li>
        </ol>
        <p>
         Following model conversion, some input-agnostic operations are conducted
for optimization purposes prior to model deployment, including constant
folding, operator fusion, operator replacement, and operator reordering
— optimization methods discussed earlier in this book. For instance,
constant folding is usually performed during the compilation executed on
the compiler frontend, whereas, operator fusion and partition are often
performed (depending on the backend hardware support) once the
compilation is complete. However, some optimization operations can only
be performed in their entirety during the deployment phase.
        </p>
        <div class="figure align-default" id="id1">
         <span id="ch-deploy-fusion-storage">
         </span>
         <img alt="../_images/ch09-storage.png" src="../_images/ch09-storage.png"/>
         <p class="caption">
          <span class="caption-number">
           Fig. 9.2.1
          </span>
          <span class="caption-text">
           Layered computer storagearchitecture
          </span>
          <a class="headerlink" href="#id1" title="Permalink to this image">
           ¶
          </a>
         </p>
        </div>
       </div>
       <div class="section" id="operator-fusion">
        <span id="ch-deploy-kernel-fusion">
        </span>
        <h2>
         <span class="section-number">
          9.2.2.
         </span>
         Operator Fusion
         <a class="headerlink" href="#operator-fusion" title="Permalink to this heading">
          ¶
         </a>
        </h2>
        <p>
         Operator fusion involves combining multiple operators in a deep neural
network (DNN) model into a new operator based on certain rules, reducing
the inference latency and power consumption by lowering the computation
workload and load/store overhead during online inference.
        </p>
        <p>
         The two main performance benefits brought by operator fusion are as
follows: First, it maximizes the utilization of registers and caches.
And second, because it combines operators, the load/store time between
the CPU and memory is reduced. Figure
         <a class="reference internal" href="#ch-deploy-fusion-storage">
          <span class="std std-numref">
           Fig. 9.2.1
          </span>
         </a>
         shows the architecture of a
computer’s storage system. While the storage capacity increases from the
level-1 cache (L1) to hard disk, so too does the time for reading data.
After operator fusion is performed, the previous computation result can
be temporarily stored in the CPU’s register or cache where the next
computation can directly read the result, reducing the number of I/O
operations on the memory. Furthermore, operator fusion allows some
computation to be completed in advance, eliminating redundant or even
cyclic redundant computing during forward computation.
        </p>
        <div class="figure align-default" id="id2">
         <span id="ch-deploy-conv-bn-fusion">
         </span>
         <img alt="../_images/ch09-conv-bn-fusion.png" src="../_images/ch09-conv-bn-fusion.png"/>
         <p class="caption">
          <span class="caption-number">
           Fig. 9.2.2
          </span>
          <span class="caption-text">
           Convolution + Batchnorm operatorfusion
          </span>
          <a class="headerlink" href="#id2" title="Permalink to this image">
           ¶
          </a>
         </p>
        </div>
        <p>
         To describe the principle of operator fusion, we will use two operators,
Convolution and Batchnorm, as shown in Figure
         <a class="reference internal" href="#ch-deploy-conv-bn-fusion">
          <span class="std std-numref">
           Fig. 9.2.2
          </span>
         </a>
         . In the figure, the solid-colored
boxes indicate operators, the resulting operators after fusion is
performed are represented by hatched boxes, and the weights or constant
tensors of operators are outlined in white. The fusion can be understood
as the simplification of an equation. The computation of Convolution is
expressed as Equation
         <code class="xref eq docutils literal notranslate">
          <span class="pre">
           ch-deploy/conv-equation
          </span>
         </code>
         .
        </p>
        <div class="math notranslate nohighlight" id="equation-chapter-model-deployment-conversion-to-inference-model-and-model-optimization-0">
         <span class="eqno">
          (9.2.1)
          <a class="headerlink" href="#equation-chapter-model-deployment-conversion-to-inference-model-and-model-optimization-0" title="Permalink to this equation">
           ¶
          </a>
         </span>
         \[\bf{Y_{\rm conv}}=\bf{W_{\rm conv}}\cdot\bf{X_{\rm conv}}+\bf{B_{\rm conv}}\]
        </div>
        <p>
         :eqlabel:
         <code class="docutils literal notranslate">
          <span class="pre">
           equ:ch-deploy/conv-equation
          </span>
         </code>
        </p>
        <p>
         Here, we do not need to understand what each variable means. Instead, we
only need to keep in mind that Equation
         <code class="xref eq docutils literal notranslate">
          <span class="pre">
           ch-deploy/conv-equation
          </span>
         </code>
         is an equation for
         <span class="math notranslate nohighlight">
          \(\bf{Y_{\rm conv}}\)
         </span>
         with respect to
         <span class="math notranslate nohighlight">
          \(\bf{X_{\rm conv}}\)
         </span>
         , and
other symbols are constants.
        </p>
        <p>
         Equation
         <code class="xref eq docutils literal notranslate">
          <span class="pre">
           ch-deploy/bn-equation
          </span>
         </code>
         is about the computation of
Batchnorm:
        </p>
        <div class="math notranslate nohighlight" id="equation-chapter-model-deployment-conversion-to-inference-model-and-model-optimization-1">
         <span class="eqno">
          (9.2.2)
          <a class="headerlink" href="#equation-chapter-model-deployment-conversion-to-inference-model-and-model-optimization-1" title="Permalink to this equation">
           ¶
          </a>
         </span>
         \[\bf{Y_{\rm bn}}=\gamma\frac{\bf{X_{\rm bn}}-\mu_{\mathcal{B}}}{\sqrt{{\sigma_{\mathcal{B}}}^{2}+\epsilon}}+\beta\]
        </div>
        <p>
         :eqlabel:
         <code class="docutils literal notranslate">
          <span class="pre">
           equ:ch-deploy/bn-equation
          </span>
         </code>
        </p>
        <p>
         Similarly, it is an equation for
         <span class="math notranslate nohighlight">
          \(\bf{Y_{\rm bn}}\)
         </span>
         with respect to
         <span class="math notranslate nohighlight">
          \(\bf{X_{\rm bn}}\)
         </span>
         . Other symbols in the equation represent
constants.
        </p>
        <p>
         As shown in Figure
         <a class="reference internal" href="#ch-deploy-conv-bn-fusion">
          <span class="std std-numref">
           Fig. 9.2.2
          </span>
         </a>
         , when the output
of Convolution is used as the input of Batchnorm, the formula of
Batchnorm is a function for
         <span class="math notranslate nohighlight">
          \(\bf{Y_{\rm bn}}\)
         </span>
         with respect to
         <span class="math notranslate nohighlight">
          \(\bf{X_{\rm conv}}\)
         </span>
         . After substituting
         <span class="math notranslate nohighlight">
          \(\bf{Y_{\rm conv}}\)
         </span>
         into
         <span class="math notranslate nohighlight">
          \(\bf{X_{\rm bn}}\)
         </span>
         and uniting and extracting the constants,
we obtain Equation
         <code class="xref eq docutils literal notranslate">
          <span class="pre">
           ch-deploy/conv-bn-equation-3
          </span>
         </code>
         .
        </p>
        <div class="math notranslate nohighlight" id="equation-chapter-model-deployment-conversion-to-inference-model-and-model-optimization-2">
         <span class="eqno">
          (9.2.3)
          <a class="headerlink" href="#equation-chapter-model-deployment-conversion-to-inference-model-and-model-optimization-2" title="Permalink to this equation">
           ¶
          </a>
         </span>
         \[\bf{Y_{\rm bn}}=\bf{A}\cdot\bf{X_{\rm conv}}+\bf{B}\]
        </div>
        <p>
         :eqlabel:
         <code class="docutils literal notranslate">
          <span class="pre">
           equ:ch-deploy/conv-bn-equation-3
          </span>
         </code>
        </p>
        <p>
         Here,
         <span class="math notranslate nohighlight">
          \(\bf{A}\)
         </span>
         and
         <span class="math notranslate nohighlight">
          \(\bf{B}\)
         </span>
         are two matrices. It can be
noticed that Equation
         <code class="xref eq docutils literal notranslate">
          <span class="pre">
           ch-deploy/conv-bn-equation-3
          </span>
         </code>
         is a
formula for computing Convolution. The preceding example shows that the
computation of Convolution and Batchnorm can be fused into an equivalent
Convolution operator. Such fusion is referred to as formula fusion.
        </p>
        <p>
         The fusion of Convolution and Batchnorm eliminates a Batchnorm
operation, thereby reducing the quantity of parameters and computation
workload are reduced, and thereby the load/store operations are also
reduced. In general, this fusion not only optimizes the power
consumption and performance during model deployment, but also brings
certain benefits in compressing the model size.
        </p>
        <p>
         Symbols that are considered as constants in the Convolution and
Batchnorm formulas during fusion are considered as parameters during
training. Performing fusion during the training process will result in
missing model parameters. Because the fusion eliminates a Batchnorm
operator and corresponding parameters from the network, the algorithm of
the DNN is changed, degrading the accuracy to unacceptable levels.
Therefore, the fusion of Convolution and Batchnorm is an optimization
method typically used during deployment. To evaluate the optimization
effect, we constructed a sample network with Convolution and Batchnorm
using MindSpore Lite. We ran the sample network and mobilenet-v2 network
for inference in dual threads on a Huawei Mate 30 smartphone to compare
the time of running 3,000 inference epochs before and after the fusion.
As shown in Table
         <code class="docutils literal notranslate">
          <span class="pre">
           ch09-conv-bn-fusion
          </span>
         </code>
         , the inference performance of
the sample network and mobilenet-v2 network is improved considerably
after the fusion — by 8.5% and 11.7% respectively. Such improvements are
achieved without bringing side effects and without requiring additional
hardware or operator libraries.
        </p>
        <span id="ch09-ch09-conv-bn-fusion">
        </span>
        <table class="docutils align-default" id="id3" style="margin-left:auto;margin-right:auto;margin-top:10px;margin-bottom:20px;">
         <caption>
          <span class="caption-number">
           Table 9.2.1
          </span>
          <span class="caption-text">
           Convolution + Batchnorm inference performance before and
after fusion (unit: ms)
          </span>
          <a class="headerlink" href="#id3" title="Permalink to this table">
           ¶
          </a>
         </caption>
         <colgroup>
          <col style="width: 42%"/>
          <col style="width: 19%"/>
          <col style="width: 39%"/>
         </colgroup>
         <thead>
          <tr class="row-odd">
           <th class="head">
            <p>
             Fusion
            </p>
           </th>
           <th class="head">
            <p>
             Sample
            </p>
           </th>
           <th class="head">
            <p>
             Mobilenet-v2
            </p>
           </th>
          </tr>
         </thead>
         <tbody>
          <tr class="row-even">
           <td>
            <p>
             Before fusion
            </p>
           </td>
           <td>
            <p>
             0.035
            </p>
           </td>
           <td>
            <p>
             15.415
            </p>
           </td>
          </tr>
          <tr class="row-odd">
           <td>
            <p>
             After fusion
            </p>
           </td>
           <td>
            <p>
             0.031
            </p>
           </td>
           <td>
            <p>
             13.606
            </p>
           </td>
          </tr>
         </tbody>
        </table>
       </div>
       <div class="section" id="operator-replacement">
        <h2>
         <span class="section-number">
          9.2.3.
         </span>
         Operator Replacement
         <a class="headerlink" href="#operator-replacement" title="Permalink to this heading">
          ¶
         </a>
        </h2>
        <p>
         The principle of operator replacement is to simplify an operator formula
by uniting like terms, extracting common factors, and employing other
mathematical methods, and then map the simplified formula to a certain
type of operators that have the same computational logic but are more
suitable for online deployment. In this way, we can reduce the
computation workload and compress the model.
        </p>
        <div class="figure align-default" id="id4">
         <span id="ch-deploy-bn-replace">
         </span>
         <img alt="../_images/ch09-bn-replace.png" src="../_images/ch09-bn-replace.png"/>
         <p class="caption">
          <span class="caption-number">
           Fig. 9.2.3
          </span>
          <span class="caption-text">
           Replacement ofBatchnorm
          </span>
          <a class="headerlink" href="#id4" title="Permalink to this image">
           ¶
          </a>
         </p>
        </div>
        <p>
         Figure
         <a class="reference internal" href="#ch-deploy-bn-replace">
          <span class="std std-numref">
           Fig. 9.2.3
          </span>
         </a>
         depicts the replacement of
Batchnorm with Scale, which is used as an example to describe the
principle of operator replacement. After decomposing Equation
         <code class="xref eq docutils literal notranslate">
          <span class="pre">
           ch-deploy/bn-equation
          </span>
         </code>
         (the Batchnorm formula) and folding the
constants, Batchnorm is defined as Equation
         <code class="xref eq docutils literal notranslate">
          <span class="pre">
           ch-deploy/replace-scale
          </span>
         </code>
        </p>
        <div class="math notranslate nohighlight" id="equation-chapter-model-deployment-conversion-to-inference-model-and-model-optimization-3">
         <span class="eqno">
          (9.2.4)
          <a class="headerlink" href="#equation-chapter-model-deployment-conversion-to-inference-model-and-model-optimization-3" title="Permalink to this equation">
           ¶
          </a>
         </span>
         \[\bf{Y_{bn}}=scale\cdot\bf{X_{bn}}+offset\]
        </div>
        <p>
         :eqlabel:
         <code class="docutils literal notranslate">
          <span class="pre">
           equ:ch-deploy/replace-scale
          </span>
         </code>
        </p>
        <p>
         where
         <strong>
          scale
         </strong>
         and
         <strong>
          offsets
         </strong>
         are scalars. This simplified formula can
be mapped to a Scale operator.
        </p>
        <p>
         Compared with the original Batchnorm formula, the simplified formula has
fewer parameters and involves less computation workload. This indicates
that operator replacement is an effective approach to optimizing the
power consumption and performance of a model during deployment. Symbols
that are considered as constants in Batchnorm during deployment are not
considered as constants during training, meaning that the replacement
can be performed only during deployment. Operator replacement reduces
the quantity of parameters and changes the structure of the model,
weakening the expressive power and reducing the accuracy of the model
during convergence.
        </p>
       </div>
       <div class="section" id="operator-reordering">
        <h2>
         <span class="section-number">
          9.2.4.
         </span>
         Operator Reordering
         <a class="headerlink" href="#operator-reordering" title="Permalink to this heading">
          ¶
         </a>
        </h2>
        <p>
         Another way of reducing the computation workload of an inference model
is to adjust the topological order of its operators according to certain
rules, on the condition that the inference accuracy is not degraded.
Common methods of operator reordering include moving cropping operators
(e.g., Slice, StrideSlice, and Crop) forward, and reordering Reshape,
Transpose, and BinaryOp.
        </p>
        <div class="figure align-default" id="id5">
         <span id="ch-deploy-crop-reorder">
         </span>
         <img alt="../_images/ch09-crop-reorder.png" src="../_images/ch09-crop-reorder.png"/>
         <p class="caption">
          <span class="caption-number">
           Fig. 9.2.4
          </span>
          <span class="caption-text">
           Reordering ofCrop
          </span>
          <a class="headerlink" href="#id5" title="Permalink to this image">
           ¶
          </a>
         </p>
        </div>
        <p>
         Crop is used to cut a part out of the input feature map as the output.
After Crop is executed, the size of the feature map is reduced. As shown
in Figure
         <a class="reference internal" href="#ch-deploy-crop-reorder">
          <span class="std std-numref">
           Fig. 9.2.4
          </span>
         </a>
         , moving Crop forward to cut
the feature map before other operators reduces the computation workload
of subsequent operators, thereby improving the inference performance in
the deployment phase. Such improvement is related to the operator
parameters. Note, however, that Crop can be moved forward only along
element-wise operators.
        </p>
        <p>
         The experiment result above proves that optimizing models before
inference makes it possible to significantly reduce the latency, power
consumption, and memory usage.
        </p>
       </div>
      </div>
     </div>
     <div class="side-doc-outline">
      <div class="side-doc-outline--content">
       <div class="localtoc">
        <p class="caption">
         <span class="caption-text">
          Table Of Contents
         </span>
        </p>
        <ul>
         <li>
          <a class="reference internal" href="#">
           9.2. Conversion to Inference Model and Model Optimization
          </a>
          <ul>
           <li>
            <a class="reference internal" href="#model-conversion">
             9.2.1. Model Conversion
            </a>
           </li>
           <li>
            <a class="reference internal" href="#operator-fusion">
             9.2.2. Operator Fusion
            </a>
           </li>
           <li>
            <a class="reference internal" href="#operator-replacement">
             9.2.3. Operator Replacement
            </a>
           </li>
           <li>
            <a class="reference internal" href="#operator-reordering">
             9.2.4. Operator Reordering
            </a>
           </li>
          </ul>
         </li>
        </ul>
       </div>
      </div>
     </div>
     <div class="clearer">
     </div>
    </div>
    <div class="pagenation">
     <a accesskey="P" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" href="Overview.html" id="button-prev" role="botton">
      <i class="pagenation-arrow-L fas fa-arrow-left fa-lg">
      </i>
      <div class="pagenation-text">
       <span class="pagenation-direction">
        Previous
       </span>
       <div>
        9.1. Overview
       </div>
      </div>
     </a>
     <a accesskey="N" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" href="Model_Compression.html" id="button-next" role="botton">
      <i class="pagenation-arrow-R fas fa-arrow-right fa-lg">
      </i>
      <div class="pagenation-text">
       <span class="pagenation-direction">
        Next
       </span>
       <div>
        9.3. Model Compression
       </div>
      </div>
     </a>
    </div>
   </main>
  </div>
 </body>
</html>
